{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse data from ebike datalogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install autokeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import tensorflow as tf\n",
    "#import autokeras as ak\n",
    "import gc\n",
    "\n",
    "import secrets\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree, to_graphviz\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "import glob \n",
    "import os\n",
    "import scipy as sp\n",
    "import scipy.signal as sg\n",
    "\n",
    "\n",
    "from butter_filter import signal_filter\n",
    "from gen_plots import display_interesting_variables, display_all_variables\n",
    "from Battery_Kalman.soc_estimator import SocEstimator\n",
    "from Battery_Kalman.battery import Battery\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import geopandas as gpd\n",
    "from convertbng.util import convert_bng, convert_lonlat\n",
    "from sklearn.neighbors import BallTree\n",
    "sns.set_theme()\n",
    "\n",
    "# DANGEROUS DONT DO\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "\n",
    "\n",
    "#px.set_mapbox_access_token(open(\".mapbox_token\").read())\n",
    "\n",
    "BATTERY_ENERGY_CAPACITY = 752.4 # Kilo Joules\n",
    "\n",
    "#raw_data_path = \"D:/OneDrive - Imperial College London/University Storage/Masters project/data_storage/\"\n",
    "raw_data_path = \"/home/medad/Downloads/MastersProject/Bike_logger/Data_analysis/data_storage/data_storage/\"\n",
    "\n",
    "# Number of PAS magnets\n",
    "N_PAS_MAGNETS = 12\n",
    "\n",
    "# Pressure (mbar) at sea level where the readings are being taken.  \n",
    "qnh=1032.57\n",
    "\n",
    "ROAD_FEATURES_PKL_FP = \"road_features.pkl\"\n",
    "\n",
    "def load_road_features_from_raw():\n",
    "\n",
    "    # Grid references for London: https://getoutside.ordnancesurvey.co.uk/guides/beginners-guide-to-grid-references/\n",
    "    # Read SHx files\n",
    "    files = [\n",
    "    \"SP_RoadNode.shx\",\n",
    "    \"TL_RoadNode.shx\",\n",
    "    \"SU_RoadNode.shx\",\n",
    "    \"TQ_RoadNode.shx\",\n",
    "     #\"NC_RoadNode.shx\"\n",
    "\n",
    "    ]\n",
    "\n",
    "    path = raw_data_path+\"oproad_essh_gb/data/\"\n",
    "\n",
    "    paths = [path+file for file in files]\n",
    "\n",
    "    road_features_geo_df = pd.concat(map(gpd.read_file, paths))\n",
    "\n",
    "    road_features_geo_df['Longitude (°)'], road_features_geo_df['Latitude (°)'] = convert_lonlat(road_features_geo_df.geometry.x, road_features_geo_df.geometry.y)\n",
    "\n",
    "    road_features_geo_df.to_pickle(ROAD_FEATURES_PKL_FP)\n",
    "    \n",
    "    return road_features_geo_df\n",
    "    \n",
    "\n",
    "def get_road_features(reload=False):\n",
    "    \n",
    "    if reload:\n",
    "        road_features_geo_df = load_road_features_from_raw()\n",
    "    else:\n",
    "        road_features_geo_df = pd.read_pickle(ROAD_FEATURES_PKL_FP)\n",
    "    \n",
    "    return road_features_geo_df\n",
    "\n",
    "# read raw data\n",
    "def read_file(filepath):\n",
    "    my_cols = range(19)\n",
    "\n",
    "    date_parser=lambda x: pd.to_datetime(x, errors=\"coerce\", format = \"%Y-%m-%dT%H:%M:%S.%fZ\", utc=True)\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(filepath,\n",
    "                names=my_cols,\n",
    "                engine='c',\n",
    "                parse_dates=[0],\n",
    "                date_parser=date_parser)\n",
    "\n",
    "\n",
    "    df.rename(columns={0: 'Datetime (UTC)',\n",
    "                           1: 'sensor',\n",
    "                          }, inplace=True)    \n",
    "    \n",
    "    df.dropna(inplace=True, subset=['Datetime (UTC)'])\n",
    "    \n",
    "    df.sort_values(by='Datetime (UTC)',inplace = True)\n",
    "\n",
    "\n",
    "    df = df[~(df['Datetime (UTC)'] < '2020-03-12 18:46:00')]\n",
    "    \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_df_signal(df, input_name, output_name, highcut_f):\n",
    "    df[output_name] = signal_filter(df[input_name], highcut=highcut_f, method='butterworth_ba', order=5)\n",
    "    return df\n",
    "\n",
    "\n",
    "def energy_from_power_time(datetime_series, power_series):\n",
    "    \"\"\"\n",
    "    Return power in kilo joules\n",
    "    \"\"\"\n",
    "    max_seconds = 1\n",
    "    \n",
    "    time_delta = datetime_series.diff().dt.total_seconds().fillna(0)\n",
    "    energy = power_series*time_delta\n",
    "    \n",
    "    energy = energy[time_delta < max_seconds]\n",
    "    \n",
    "    return energy.sum()/1000000\n",
    "\n",
    "def pulse_width_pas_to_rpm(pulse_width):   \n",
    "    return (1000000/pulse_width/N_PAS_MAGNETS)*60\n",
    "\n",
    "def pulse_width_to_rpm(pulse_width):   \n",
    "    return (1000000/pulse_width)*60\n",
    "\n",
    "def get_altitude(pressure,temperature):\n",
    "    altitude = ((pow((qnh / pressure), (1.0 / 5.257)) - 1) * (temperature + 273.15)) / 0.0065\n",
    "    # The temperature (°C) should be the outdoor temperature (°C). \n",
    "    # Use the manual_temperature (°C) variable if temperature (°C) adjustments are required.\n",
    "    return altitude\n",
    "\n",
    "def insert_time(row):\n",
    "    return row['Datetime (UTC)'].replace(minute=int(row['minute']),second=int(row['second']),microsecond=int(row['millisecond']*1000))\n",
    "\n",
    "def process_gps(df):\n",
    "    mask = df[\"sensor\"] == 'gps'\n",
    "    df_gps = df[mask]\n",
    "\n",
    "    df_gps.rename(columns={2: 'hour',\n",
    "                           3: 'minute',\n",
    "                           4: 'second',\n",
    "                           5: 'millisecond',\n",
    "                           6: 'Latitude (°)',\n",
    "                           7: 'Longitude (°)',\n",
    "                           8: 'GPS altitude (m)',\n",
    "                           9: 'GPS Horizontal Speed (km/h)',\n",
    "                           10: 'sats',\n",
    "                           11: 'gnssFixOK',\n",
    "                           12: 'fix_type',\n",
    "                           13: 'vehicle_heading',\n",
    "                           14: 'horizontal_accuracy', # Horizontal accuracy estimate: mm\n",
    "                           15: 'vertical_accuracy',   #  Vertical accuracy estimate: mm\n",
    "                           16: 'speed_accuracy',     # Speed accuracy estimate: mm/s\n",
    "                           17: 'heading_accuracy'    # Heading accuracy estimate (both motion and vehicle): deg\n",
    "                          }, inplace=True)\n",
    "\n",
    "    \n",
    "    df_gps['Datetime (UTC)'] = df_gps.apply(lambda r: insert_time(r), axis=1)\n",
    "    df_gps.sort_values(by='Datetime (UTC)',inplace = True)\n",
    "    \n",
    "    df_gps = df_gps[df_gps['gnssFixOK'] == 1]\n",
    "\n",
    "    \n",
    "    # There is a wierd time offset between GPS readings and all other sensor timestamps. It \n",
    "    # has been determined to be 9.5 seconds by hand adjustment. Not machine aligned.\n",
    "    offset = 9.5 # seconds\n",
    "    df_gps['Datetime (UTC)'] = df_gps['Datetime (UTC)'] - pd.Timedelta(offset, unit='s')\n",
    "\n",
    "    \n",
    "\n",
    "    time_delta = df_gps['Datetime (UTC)'].diff().dt.total_seconds().fillna(0)\n",
    "    df_gps['GPS Horizontal Acceleration (km/h^2)'] = df_gps['GPS Horizontal Speed (km/h)'].diff()/time_delta\n",
    "    \n",
    "    \n",
    "    x = df_gps['Longitude (°)'].diff().fillna(0)\n",
    "    y = df_gps['Latitude (°)'].diff().fillna(0)\n",
    "    \n",
    "    x = signal_filter(x, highcut=100, method='butterworth_ba', order=5)\n",
    "    y = signal_filter(y, highcut=100, method='butterworth_ba', order=5)\n",
    "\n",
    "    phi, df_gps['heading (radians)'] = cart2pol(x, y)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Create a BallTree \n",
    "    tree = BallTree(road_features_geo_df[['Longitude (°)', 'Latitude (°)']].values, leaf_size=2)\n",
    "\n",
    "    # Query the BallTree on each feature from 'appart' to find the distance\n",
    "    # to the nearest 'pharma' and its id\n",
    "    df_gps['Distance to nearest road feature (°)'], df_gps['id_nearest'] = tree.query(\n",
    "        df_gps[['Longitude (°)', 'Latitude (°)']].values, # The input array for the query\n",
    "        k=1, # The number of nearest neighbors\n",
    "    )\n",
    "\n",
    "    \n",
    "    add_arc_radius_to_gps(df_gps,x,y)\n",
    "    \n",
    "    \n",
    "\n",
    "    df_gps.dropna(axis=1, how='all',inplace=True)\n",
    "    df_gps.head()\n",
    "    \n",
    "    return df_gps\n",
    "\n",
    "\n",
    "def add_arc_radius_to_gps(df_gps, x, y):\n",
    "        \n",
    "    r,h,k = findCircle(\n",
    "        np.roll(x, -1), np.roll(y, -1),\n",
    "        x, y,\n",
    "        np.roll(x, 1), np.roll(y, 1)\n",
    "    )\n",
    "    \n",
    "    #print(r,h,k)\n",
    "    \n",
    "    r = pd.Series(r)\n",
    "    r.index = df_gps.index\n",
    "\n",
    "    \n",
    "    \n",
    "    df_gps['Road Curvature (m radius)'] = r\n",
    "\n",
    "\n",
    "# vectorized haversine function\n",
    "def haversine(lat1, lon1, lat2, lon2, to_radians=True, earth_radius=6371):\n",
    "\n",
    "    \"\"\"\n",
    "    slightly modified version: of http://stackoverflow.com/a/29546836/2901002\n",
    "\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees or in radians)\n",
    "\n",
    "    All (lat, lon) coordinates must have numeric dtypes and be of equal length.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if to_radians:\n",
    "        lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    a = np.sin((lat2-lat1)/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin((lon2-lon1)/2.0)**2\n",
    "\n",
    "    return earth_radius * 2 * np.arcsin(np.sqrt(a)) * 1000\n",
    "\n",
    "def get_horizontal_distance(df):\n",
    "    return haversine(df['Latitude (°)'].shift(1), df['Longitude (°)'].shift(1), df['Latitude (°)'], df['Longitude (°)'])\n",
    "\n",
    "\n",
    "def add_slope_to_gps(df_gps, df_baro):\n",
    "    \n",
    "    \n",
    "    df_baro_gps = pd.merge_asof(df_gps, df_baro, on = 'Datetime (UTC)', direction = 'forward')\n",
    "\n",
    "    df_baro_gps['Barometric Altitude Filtered (m)'] = signal_filter(df_baro_gps['Barometric Altitude (m)'], highcut=10, method='butterworth_ba', order=2)\n",
    "    \n",
    "    delta_altitude = df_baro_gps['Barometric Altitude Filtered (m)'].diff()\n",
    "    \n",
    "    cols = ['Longitude (°)','Latitude (°)']    \n",
    "    \n",
    "    delta_horizontal_distance =  pd.Series(get_horizontal_distance(df_gps))\n",
    "    print(delta_horizontal_distance.describe())\n",
    "    \n",
    "    delta_horizontal_distance.replace([np.nan], 0, inplace=True)\n",
    "\n",
    "    delta_horizontal_distance_filtered = pd.Series(signal_filter(delta_horizontal_distance, highcut=100, method='butterworth_ba', order=2))\n",
    "\n",
    "    slope = 100 * delta_altitude/delta_horizontal_distance_filtered\n",
    "    \n",
    "    slope.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    \n",
    "    slope.index = df_gps.index\n",
    "    df_gps.loc[:, 'Road Grade (%)'] = slope\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def process_imu(df):\n",
    "    mask = df[\"sensor\"] == 'imu'\n",
    "    df_imu = df[mask]\n",
    "    \n",
    "    if df_imu.empty:\n",
    "        return\n",
    "\n",
    "    df_imu.rename(columns={2: 'acceleration X (m/s^2)',\n",
    "                           3: 'acceleration Y (m/s^2)',\n",
    "                           4: 'acceleration Z (m/s^2)',\n",
    "                           5: 'Angular Velocity X (rad/s)',\n",
    "                           6: 'Angular Velocity Y (rad/s)',\n",
    "                           7: 'Angular Velocity Z (rad/s)',\n",
    "                          }, inplace=True)\n",
    "\n",
    "    df_imu.dropna(axis=1, how='all',inplace=True)\n",
    "    \n",
    "    df_imu = filter_df_signal(df_imu, 'Angular Velocity X (rad/s)', \"gyro_x_filtered\", 10 )\n",
    "    df_imu = filter_df_signal(df_imu, 'acceleration X (m/s^2)', \"acceleration_x_filtered\", 10 )\n",
    "\n",
    "\n",
    "    return df_imu\n",
    "\n",
    "def process_brake(df):\n",
    "    mask = df[\"sensor\"] == 'Brake State'\n",
    "    df_brake = df[mask]\n",
    "\n",
    "    df_brake.rename(columns={2: 'Brake State',\n",
    "                          }, inplace=True)\n",
    "\n",
    "    df_brake.dropna(axis=1, how='all',inplace=True)\n",
    "    return df_brake\n",
    "\n",
    "\n",
    "def process_pas(df):\n",
    "    mask = df[\"sensor\"] == 'pas'\n",
    "    df_pas = df[mask]\n",
    "    \n",
    "    if df_pas.empty:\n",
    "        return\n",
    "\n",
    "\n",
    "    df_pas.rename(columns={2: 'pulse_delay_us',\n",
    "                          }, inplace=True)\n",
    "    df_pas.dropna(axis=1, how='all',inplace=True)\n",
    "    df_pas = df_pas[df_pas['pulse_delay_us'] > 4000]\n",
    "\n",
    "    df_pas['Pedal Rotation Speed (RPM)'] = df_pas.apply(lambda x: pulse_width_pas_to_rpm(x['pulse_delay_us']), axis=1)\n",
    "\n",
    "    df_pas.head()\n",
    "    \n",
    "    return df_pas\n",
    "    \n",
    "def process_motor_speed(df, df_gps):\n",
    "    mask = df[\"sensor\"] == 'motor_speed'\n",
    "    df_ms = df[mask]\n",
    "    \n",
    "    \n",
    "    if df_ms.empty:\n",
    "        return\n",
    "\n",
    "    df_ms.rename(columns={2: 'pulse_delay_us',\n",
    "                          }, inplace=True)\n",
    "    \n",
    "    df_ms.dropna(axis=1, how='all',inplace=True)\n",
    "    \n",
    "    df_ms = df_ms[df_ms['pulse_delay_us'] > 15000]\n",
    "\n",
    "\n",
    "    df_ms['Motor Rotation Speed (RPM)'] = df_ms.apply(lambda x: pulse_width_to_rpm(x['pulse_delay_us']), axis=1)\n",
    "    \n",
    "    df_ms_merged = pd.merge_asof(df_ms, df_gps, on = 'Datetime (UTC)', direction = 'nearest')\n",
    "    \n",
    "    multiplier = df_ms_merged['GPS Horizontal Speed (km/h)'].div(df_ms_merged['Motor Rotation Speed (RPM)'], axis = 0).mean()\n",
    "\n",
    "    \n",
    "    \n",
    "    df_ms['Motor Rotation Speed (RPM)'] = df_ms['Motor Rotation Speed (RPM)'] * multiplier\n",
    "    \n",
    "    \n",
    "    time_delta = df_ms['Datetime (UTC)'].diff().dt.total_seconds().fillna(0)\n",
    "    df_ms['filtered_motor_rpm'] = signal_filter(df_ms['Motor Rotation Speed (RPM)'], highcut=100, method='butterworth_ba', order=5)\n",
    "    df_ms['motor_acceleration'] = df_ms[\"filtered_motor_rpm\"].diff()/time_delta\n",
    "\n",
    "\n",
    "    \n",
    "    return df_ms\n",
    "\n",
    "def process_ina(df):    \n",
    "    mask = df[\"sensor\"] == 'ina226'\n",
    "    df_ina = df[mask]\n",
    "    \n",
    "    SHUNT_RESISTANCE = 0.00215 # ohms\n",
    "\n",
    "    df_ina.rename(columns={2: 'INA226 ID',\n",
    "                           3: 'Voltage (V)',\n",
    "                           4: 'Shunt Voltage Drop (V)',\n",
    "                           5: 'Current_uncalibrated',\n",
    "                           6: 'Power_uncalibrated',\n",
    "                          }, inplace=True)\n",
    "    df_ina.dropna(axis=1, how='all',inplace=True)\n",
    "    df_ina.reset_index()\n",
    "\n",
    "\n",
    "    df_ina = df_ina[df_ina['Voltage (V)'] != 0]\n",
    "    \n",
    "    df_ina['Current (mA)'] = df_ina['Shunt Voltage Drop (V)'] / SHUNT_RESISTANCE\n",
    "    df_ina['Power (mW)'] = df_ina['Current (mA)'] * df_ina['Voltage (V)']\n",
    "\n",
    "    df_ina[\"Power_averaged\"] = signal_filter(df_ina['Power (mW)'], highcut=6, method='butterworth_ba', order=2)\n",
    "#     df_ina[\"Current_averaged\"] = signal_filter(df_ina['Current (mA)'], highcut=6, method='butterworth_ba', order=2)\n",
    "#     df_ina[\"Voltage_V_averaged\"] = signal_filter(df_ina['Voltage (V)'], highcut=6, method='butterworth_ba', order=2)\n",
    "\n",
    "\n",
    "    print(\"Total Energy Consumption[KiloJoules]\",energy_from_power_time(df_ina['Datetime (UTC)'],df_ina['Power (mW)']))\n",
    "    df_ina.head()\n",
    "    \n",
    "    return df_ina\n",
    "\n",
    "def process_baro(df,df_ms, df_gps):\n",
    "    mask = df[\"sensor\"] == 'baro'\n",
    "    df_baro = df[mask]\n",
    "\n",
    "    df_baro.rename(columns={2: 'temperature (°C)',\n",
    "                           3: 'Pressure (mbar)',\n",
    "                           4: 'humidity (RH%)',\n",
    "                          }, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_baro['Barometric Altitude (m)'] = df_baro.apply(lambda x: get_altitude(x['Pressure (mbar)'], x['temperature (°C)']), axis=1)\n",
    "    \n",
    "    df_baro = df_baro[df_baro['Barometric Altitude (m)'] > -30] # Filter out unrealistic pressures\n",
    "    \n",
    "    df_baro['Barometric Altitude Filtered (m)'] = signal_filter(df_baro['Barometric Altitude (m)'], highcut=10, method='butterworth_ba', order=2)\n",
    "\n",
    "    df_baro_merged = pd.merge_asof(df_baro, df_gps, on = 'Datetime (UTC)', direction = 'forward')\n",
    "    \n",
    "    \n",
    "    \n",
    "    offset = df_baro_merged['Barometric Altitude (m)'].sub(df_baro_merged['GPS altitude (m)'], axis = 0).mean()\n",
    "    \n",
    "\n",
    "    time_delta = df_baro['Datetime (UTC)'].diff().dt.total_seconds().fillna(0)\n",
    "    df_baro['Vertical Rise (m)'] = df_baro['Barometric Altitude Filtered (m)'].diff()\n",
    "    df_baro['Vertical Velocity (m/s)'] = df_baro['Vertical Rise (m)']/time_delta\n",
    "    \n",
    "    df_baro['Barometric_Altitude_Uncalibrated'] = df_baro['Barometric Altitude (m)']\n",
    "    df_baro['Barometric Altitude (m)'] = df_baro['Barometric Altitude (m)'] - offset\n",
    "    df_baro['Barometric Altitude Filtered (m)'] = df_baro['Barometric Altitude Filtered (m)'] - offset\n",
    "\n",
    "\n",
    "\n",
    "    df_baro.dropna(axis=1, how='all',inplace=True)\n",
    "\n",
    "    df_baro.head()\n",
    "    \n",
    "    return df_baro\n",
    "\n",
    "def process(df):\n",
    "    print(\"Start GPS process\")\n",
    "    df_gps = process_gps(df)\n",
    "    print(\"GPS process DONE....\")\n",
    "    \n",
    "    df_pas = process_pas(df)\n",
    "    print(\"PAS process DONE....\")\n",
    "    \n",
    "    df_ms = process_motor_speed(df, df_gps)\n",
    "    print(\"Motor Speed process DONE....\")\n",
    "\n",
    "    df_ina = process_ina(df)\n",
    "    print(\"INA226 process DONE....\")\n",
    "\n",
    "    df_baro = process_baro(df,df_ms,df_gps)\n",
    "    print(\"Barometer process DONE....\")\n",
    "    \n",
    "    add_slope_to_gps(df_gps, df_baro)\n",
    "    print(\"Add slope data DONE....\")\n",
    "\n",
    "    df_imu = process_imu(df)\n",
    "    print(\"IMU process DONE....\")\n",
    "\n",
    "    df_brake = process_brake(df)\n",
    "    print(\"Brake process DONE....\")\n",
    "\n",
    "\n",
    "    return df_ina, df_gps, df_baro, df_pas, df_ms, df_imu, df_brake\n",
    "\n",
    "\n",
    "def process_charge_data(fps):\n",
    "    dfs  = [read_file(fp) for fp in fps]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df_ina = process_ina(df)\n",
    "    return df_ina\n",
    "\n",
    "def display_charge_data(df_ina):\n",
    "    \n",
    "    \n",
    "    FEATURES = [\"Voltage_V_averaged\",\"Current_averaged\",\"Power_averaged\"]\n",
    "    TITLES = [\"Battery Voltage[V]\",\"Current[mA]\",\"Power[mW]\"]\n",
    "\n",
    "    N_FEATURES = len(FEATURES)\n",
    "    fig = make_subplots(rows=N_FEATURES, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01)\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "    for i, feature in enumerate(FEATURES):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_ina.index,\n",
    "            y=df_ina[feature],\n",
    "            name=feature,\n",
    "            hoverinfo='y'),\n",
    "            row=i+1, col=1)\n",
    "        \n",
    "#         non_averaged_feature = feature.replace(\"_averaged\",\"\")\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=df_ina.index,\n",
    "#             y=df_ina[non_averaged_feature],\n",
    "#             name=non_averaged_feature,\n",
    "#             hoverinfo='y'),\n",
    "#             row=i+1, col=1)\n",
    "\n",
    "        fig.update_yaxes(title_text=TITLES[i], row=i+1, col=1)\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"Power Parameters\")\n",
    "\n",
    "    fig.write_html(\"output/Charging_Power_variables.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "\n",
    "params_x_for_ml = ['temperature (°C)', \n",
    "                   'Pressure (mbar)', \n",
    "                   'humidity (RH%)',\n",
    "                   'Barometric Altitude Filtered (m)',\n",
    "                   'Road Grade (%)',\n",
    "                   'Latitude (°)',\n",
    "                   'Longitude (°)',\n",
    "                   'GPS altitude (m)',\n",
    "                   'heading (radians)',\n",
    "                   'Distance to nearest road feature (°)',\n",
    "                   'Road Curvature (m radius)',\n",
    "\n",
    "                   \n",
    "#                    'GPS Horizontal Speed (km/h)',\n",
    "#                    'SOC',\n",
    "                   \n",
    "                   \n",
    "#                     'Vertical Velocity (m/s)',\n",
    "#                     'Pedal Rotation Speed (RPM)',\n",
    "#                     'Motor Rotation Speed (RPM)',\n",
    "#                     'acceleration X (m/s^2)',\n",
    "#                     'acceleration Y (m/s^2)',\n",
    "#                     'acceleration Z (m/s^2)',\n",
    "#                     'Angular Velocity X (rad/s)',\n",
    "#                     'Angular Velocity Y (rad/s)',\n",
    "#                     'Angular Velocity Z (rad/s)',\n",
    "\n",
    "                 ]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'Barometric Altitude (m)',\n",
    "# 'Barometric Altitude Filtered (m)',\n",
    "# 'Vertical Velocity (m/s)',\n",
    "# 'Pedal Rotation Speed (RPM)',\n",
    "# 'Motor Rotation Speed (RPM)',\n",
    "# 'acceleration X (m/s^2)',\n",
    "# 'acceleration Y (m/s^2)',\n",
    "# 'acceleration Z (m/s^2)',\n",
    "# 'Angular Velocity X (rad/s)',\n",
    "# 'Angular Velocity Y (rad/s)',\n",
    "# 'Angular Velocity Z (rad/s)',\n",
    "# 'Brake State',\n",
    "\n",
    "params_y_for_ml = 'Power (mW)'\n",
    "\n",
    "params_x_for_ml_soc = ['temperature (°C)', 'Voltage (V)', 'Current (mA)', 'Power (mW)']\n",
    "params_y_for_ml_soc = \"SOC\"\n",
    "\n",
    "\n",
    "\n",
    "def drop_sensor_column(df, column_name):\n",
    "    return df[df.columns.difference([column_name])]\n",
    "\n",
    "    \n",
    "    \n",
    "def gen_ml_data(dataframes):\n",
    "    \"\"\"\n",
    "    The first data frame in dataframes should have the highest datarate\n",
    "    \"\"\"\n",
    "    \n",
    "    column_name = \"sensor\"\n",
    "    \n",
    "    \n",
    "    print(\"Dropping Sensor column....\")\n",
    "    for i in dataframes:\n",
    "        if i is not None:\n",
    "            if i.empty is False:\n",
    "                i.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "        \n",
    "    print(\"Merging Dataframes....\")\n",
    "\n",
    "    df_ml = dataframes[0] # dataframe 0 is ina226 data at 10 Hz samplerate.\n",
    "    \n",
    "    indexes = [1, 2, 3, 4, 5, 6]\n",
    "    for index in indexes:\n",
    "        if dataframes[index] is not None:\n",
    "            if dataframes[index].empty is False:\n",
    "                dataframes[index].drop('trip', axis=1, inplace=True)\n",
    "                df_ml = pd.merge_asof(df_ml, dataframes[index], on = 'Datetime (UTC)', direction = 'forward')\n",
    "    print(\"Done merging Dataframes....\")\n",
    "\n",
    "\n",
    "    return df_ml\n",
    "\n",
    "def split_x_y(df_ml, params_x_for_ml, params_y_for_ml):\n",
    "    x, y = df_ml[params_x_for_ml], df_ml[params_y_for_ml]\n",
    "    return x, y\n",
    "\n",
    "def concat_dfs(fps):\n",
    "    dfs = []\n",
    "    \n",
    "    for fp in fps:\n",
    "        df = read_file(fp)\n",
    "        trip_id = secrets.token_hex(3)\n",
    "        print(\"Trip id: \", trip_id)\n",
    "\n",
    "        df[\"trip\"] = trip_id\n",
    "        \n",
    "        dfs.append(df)\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_raw_dfs(fps):\n",
    "    df = concat_dfs(fps)\n",
    "    raw_dfs = process(df)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    return raw_dfs\n",
    "    \n",
    "\n",
    "def remove_rows_with_na_in_column(df, column):\n",
    "    return df[df[column].notna()]\n",
    "\n",
    "def process_for_ml(fps):\n",
    "    \"\"\"\n",
    "    Takes in list of file paths, concats and processes them\n",
    "    Set display_variables = True to visualise the variables.\n",
    "    \"\"\"\n",
    "    raw_dfs = get_raw_dfs(fps)\n",
    "    \n",
    "    # Highest datarate must be in the start of the list\n",
    "    df_ml = gen_ml_data(raw_dfs)\n",
    "    #df_ml = remove_rows_with_na_in_column(df_ml, \"trip\")\n",
    "    \n",
    "    \n",
    "    return df_ml, raw_dfs\n",
    "\n",
    "def get_energy_error(predicted_energy, actual_energy):\n",
    "    Error = 100 * (predicted_energy - actual_energy)/actual_energy\n",
    "    return Error\n",
    "\n",
    "\n",
    "def print_test_results(xgbr, df_ml):\n",
    "    x, y = split_x_y(df_ml, params_x_for_ml, params_y_for_ml)\n",
    "    ypred = xgbr.predict(x)\n",
    "    \n",
    "    timestamps = df_ml['Datetime (UTC)']\n",
    "    print(\"Test Results :: \")\n",
    "    error, actual_energy, predicted_energy = print_power_consumption_score(timestamps, y, ypred)\n",
    "    return error\n",
    "\n",
    "\n",
    "## SOC Calculations\n",
    "\n",
    "def coulomb_counting(df):\n",
    "    \"\"\"\n",
    "    Return SOC series, determined using coulomb counting\n",
    "    \"\"\"\n",
    "    total_capacity_As = 8.708 * 3600 # in As\n",
    "    time_interval =  df['Datetime (UTC)'].diff().dt.total_seconds().fillna(0)\n",
    "    energy  = (df['Current (mA)']/1000) * time_interval # Convert power from mA to A\n",
    "    remaining_energy = total_capacity_As - energy.cumsum()\n",
    "    soc = remaining_energy / total_capacity_As\n",
    "    return soc\n",
    "\n",
    "def thevenin_model(df):\n",
    "    \"\"\"\n",
    "    Return SOC series, determined from Current and Voltage only.\n",
    "    \"\"\"\n",
    "    total_capacity_As = 8.708 * 3600 # in As\n",
    "    time_interval = df['Datetime (UTC)'].diff().dt.total_seconds().fillna(0)\n",
    "    energy  = (df['Current (mA)']/1000) * time_interval # Convert power from mA to A\n",
    "    remaining_energy = total_capacity_As - energy.cumsum()\n",
    "    soc = remaining_energy / total_capacity_As\n",
    "    return soc\n",
    "\n",
    "def ML_trained_by_coulomb_counting(df):\n",
    "    \"\"\"\n",
    "    Return SOC series, determined from ML model, trained on Coulomb counting. \n",
    "    Uses Voltage, Current, Power and temperature (°C) to determine SOC\n",
    "    \"\"\"\n",
    "    x = df[params_x_for_ml_soc] # WARNING: df_ml_test must be a full discharge of battery from full to empty\n",
    "    soc = xgbr_SOC.predict(x)\n",
    "    return soc\n",
    "\n",
    "def add_soc_feature(df, method):\n",
    "    for trip in df[\"trip\"].unique():\n",
    "    \n",
    "        soc = method(df[df[\"trip\"]==trip])\n",
    "        \n",
    "        df.loc[df[\"trip\"]==trip,'SOC'] = soc\n",
    "\n",
    "\n",
    "    \n",
    "def score_predicted_data_xgboost(model, df_ml_test, predictor_args=None):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    ypred = model.predict(x)\n",
    "    error, actual_energy, predicted_energy = print_power_consumption_score(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    return y, ypred, error\n",
    "\n",
    "def make_predictions_xgboost(model, df_ml_test, plot=True, predictor_args=None):\n",
    "    y, ypred, error = score_predicted_data_xgboost(model, df_ml_test, predictor_args=predictor_args)\n",
    "    if plot == True:\n",
    "        plot_predicted_data(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    return error\n",
    "\n",
    "def plot_3d_plot(df_gps, df_baro, df_ina):\n",
    "    \n",
    "    df = pd.merge_asof(df_gps,df_baro , on = 'Datetime (UTC)', direction = 'nearest')\n",
    "    df = pd.merge_asof(df,df_ina , on = 'Datetime (UTC)', direction = 'nearest')\n",
    "\n",
    "    fig = go.Figure(data=go.Scatter3d(\n",
    "        x=df['Longitude (°)'],\n",
    "        y=df['Latitude (°)'],\n",
    "        z=df['Barometric Altitude Filtered (m)'],\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=df['Power (mW)'],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(\n",
    "                title='Power (mW)'\n",
    "            )\n",
    "\n",
    "        ),\n",
    "        text = 'Power:' +df['Power (mW)'].astype(str),\n",
    "        line=dict(\n",
    "            color='darkblue',\n",
    "            width=2\n",
    "        ),\n",
    "    ))\n",
    "    \n",
    "    # Fix long lat scale here: https://stackoverflow.com/a/39540339/13737285\n",
    "    \n",
    "    current_latitude = 52 # approximately london\n",
    "\n",
    "    latitude_km = 111.32\n",
    "    longitude_km = 40075 * np.cos( np.deg2rad(current_latitude) ) / 360\n",
    "    \n",
    "\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        #height=700,\n",
    "        #autosize=False,\n",
    "        scene=dict(\n",
    "            xaxis = dict(title='Longitude (°)'),\n",
    "            yaxis = dict(title='Latitude (°)'),\n",
    "            zaxis = dict(title='Barometric Altitude Filtered (m)'),\n",
    "            aspectratio=dict(x=latitude_km/longitude_km, y=1, z=1)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.write_html(\"output/gps_speed_3d.html\")\n",
    "    fig.show()\n",
    "\n",
    "def show_correlations_in_df(df):\n",
    "    \"\"\"\n",
    "    Show correlations between all the columns in df\n",
    "    \"\"\"\n",
    "    fig = px.imshow(df.corr(), title='Heatmap of co-relation between variables')\n",
    "    fig.write_html(\"output/Correlation_heatmap.html\")\n",
    "    fig.show()\n",
    "\n",
    "def remove_values_from_list(lst, value):\n",
    "    \"\"\"\n",
    "    Remove all occurances of value from lst, and return the list minus those values\n",
    "    \"\"\"\n",
    "    return list(filter((value).__ne__, lst))\n",
    "\n",
    "def plot_linear_correlations(df):\n",
    "    \"\"\"\n",
    "    plot all X-features against output variable Power\n",
    "    \"\"\"\n",
    "    col_= df.columns.tolist()\n",
    "    col_ = remove_values_from_list(col_, \"sensor_y\")\n",
    "    col_ = remove_values_from_list(col_, \"sensor_x\")\n",
    "\n",
    "    for i in col_[10:]:\n",
    "        fig = px.scatter(df, x=i, y=\"Power\", title='{0} vs Power'.format(i))\n",
    "        fig.write_html(\"output/Correlation_display_{}_vs_Power.html\".format(i))\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "def get_masked_items(df, column, items):\n",
    "    return df[df[column].isin(items)]\n",
    "\n",
    "\n",
    "\n",
    "def special_test_train_split(df_ml, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    return test, train dataframes\n",
    "    \"\"\"\n",
    "\n",
    "    train_frac = 1 - test_size\n",
    "    l = df_ml[\"trip\"].unique()\n",
    "    \n",
    "    \n",
    "    sz = len(l)\n",
    "    cut = int(train_frac * sz) #80% of the list\n",
    "    random.Random(random_state).shuffle(l) # inplace shuffle\n",
    "    train_trips = l[:cut] # first 80% of shuffled list\n",
    "    test_trips = l[cut:] # last 20% of shuffled list\n",
    "    \n",
    "    print(\"Unique Trips: \",l, \"Train Trips: \",train_trips, \"Test Trips: \",test_trips )\n",
    "\n",
    "    \n",
    "    return get_masked_items(df_ml, \"trip\", test_trips), get_masked_items(df_ml, \"trip\", train_trips)\n",
    "\n",
    "def do_join_plot(df, x_param, y_param, title):\n",
    "    p = sns.jointplot(x=x_param,\n",
    "                  y=y_param,\n",
    "                  data=df.sample(n=20000, random_state=1),\n",
    "                  kind=\"reg\",\n",
    "                  scatter_kws={\"s\": 1})\n",
    "    p.fig.suptitle(title)\n",
    "    #p.ax_joint.collections[0].set_alpha(0)\n",
    "    p.fig.tight_layout()\n",
    "    p.fig.subplots_adjust(top=0.95) # Reduce plot to make room \n",
    "\n",
    "def do_pair_plot(df, features, title, rotation=0, sample_size=20000):\n",
    "    g = sns.pairplot(\n",
    "        df[features].sample(n=sample_size, random_state=1),\n",
    "        plot_kws={\"s\": 1}\n",
    "    )\n",
    "    \n",
    "    for ax in g.axes.flatten():\n",
    "        # rotate x axis labels\n",
    "        ax.set_xlabel(ax.get_xlabel(), rotation = rotation)\n",
    "        # rotate y axis labels\n",
    "        ax.set_ylabel(ax.get_ylabel(), rotation = rotation)\n",
    "        # set y labels alignment\n",
    "        ax.yaxis.get_label().set_horizontalalignment('right')\n",
    "\n",
    "    g.fig.suptitle(\n",
    "        title,\n",
    "        y=1.001 # y= some height>1\n",
    "    ) \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Python3 implementation of the approach\n",
    "from math import sqrt\n",
    " \n",
    "# Function to find the circle on\n",
    "# which the given three points lie\n",
    "def findCircle(x1, y1, x2, y2, x3, y3) :\n",
    "    \"\"\"\n",
    "    Return radius and center of circle, given 3 bounding points of circle.\n",
    "    \"\"\"    \n",
    "    \n",
    "    x12 = x1 - x2;\n",
    "    x13 = x1 - x3;\n",
    " \n",
    "    y12 = y1 - y2;\n",
    "    y13 = y1 - y3;\n",
    " \n",
    "    y31 = y3 - y1;\n",
    "    y21 = y2 - y1;\n",
    " \n",
    "    x31 = x3 - x1;\n",
    "    x21 = x2 - x1;\n",
    " \n",
    "    # x1^2 - x3^2\n",
    "    sx13 = np.power(x1, 2) - np.power(x3, 2);\n",
    " \n",
    "    # y1^2 - y3^2\n",
    "    sy13 = np.power(y1, 2) - np.power(y3, 2);\n",
    " \n",
    "    sx21 = np.power(x2, 2) - np.power(x1, 2);\n",
    "    sy21 = np.power(y2, 2) - np.power(y1, 2);\n",
    "    \n",
    "\n",
    "    f = (sx13 * x12 + sy13 * x12 + sx21 * x13 + sy21 * x13) / (2 * (y31 * x12 - y21 * x13))\n",
    "    g = (sx13 * y12 + sy13 * y12 + sx21 * y13 + sy21 * y13) / (2 * (x31 * y12 - x21 * y13))\n",
    " \n",
    "    c = -np.power(x1, 2) - np.power(y1, 2) - 2 * g * x1 - 2 * f * y1\n",
    " \n",
    "\n",
    "    # eqn of circle be x^2 + y^2 + 2*g*x + 2*f*y + c = 0\n",
    "    # where centre is (h = -g, k = -f) and\n",
    "    # radius r as r^2 = h^2 + k^2 - c\n",
    "    h = -g;\n",
    "    k = -f;\n",
    "    sqr_of_r = h * h + k * k - c;\n",
    " \n",
    "    # r is the radius\n",
    "    r = np.sqrt(sqr_of_r);\n",
    "     \n",
    "    return r,h,k\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"LOADING ROAD FEATURES......\")\n",
    "road_features_geo_df = get_road_features(reload=False) # set to true if it has not been loaded before\n",
    "print(\"Done ROAD FEATURES......\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# No need to run if df_ml has been saved\n",
    "\n",
    "#!/usr/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "filepaths = [\n",
    "#       'hampsted_trip_1-4-2021.csv',\n",
    "    \n",
    "#     'data_19-4-21.csv',\n",
    "#      'data_icah_20-4-21.csv',\n",
    "#     'data_27-4-21.csv',\n",
    "#     'data_28-4-21.csv',\n",
    "#     'data_6-5-21.csv',\n",
    "#     'data_8-5-2021.csv',\n",
    "#     'data_10-5-21.csv',\n",
    "#     'data_15-5-21.csv',\n",
    "#     \"data_17-5-21.csv\",\n",
    "#     'data_18-5-21_enoch.csv',\n",
    "#     'data_20-5-21_v1.csv',\n",
    "    \n",
    "#     'data_20-5-21_v2.csv',\n",
    "#      'data_20-5-21_v3.csv',\n",
    "#     'data_21-5-21_v1.csv',\n",
    "#     'data_21-5-21_v2.csv',\n",
    "#     'data_25-5-21_v1.csv',\n",
    "#      'data_25-5-21_v2.csv',\n",
    "#     'data_25-5-21_v3.csv',\n",
    "#     'data_25-5-21_v4.csv',\n",
    "#     'data_25-5-21_v5.csv',\n",
    "    \n",
    "#     \"data_28-5-21_v1.csv\",\n",
    "#     \"data_28-5-21_v2.csv\",\n",
    "#     \"data_28-5-21_v3.csv\",\n",
    "#     \"data_28-5-21_v4.csv\",\n",
    "#     \"data_28-5-21_v5.csv\",\n",
    "#     \"data_28-5-21_v6.csv\",\n",
    "#     \"data_28-5-21_v7.csv\",  \n",
    "#     \"data_29-5-21_v1.csv\",\n",
    "#      \"data_29-5-21_v2.csv\",\n",
    "#     \"data_29-5-21_v2.csv\"\n",
    "    \"data_14-5-21-putney-heath-circuit.csv\"\n",
    "\n",
    "\n",
    "    \n",
    "]\n",
    "\n",
    "df_ml, raw_dfs = process_for_ml([raw_data_path+i for i in filepaths])\n",
    "\n",
    "df_ml.to_pickle(\"df_ml_putney_loop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_train = df_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_table_columns = [\n",
    "    'Datetime (UTC)',\n",
    "#     'Voltage (V)',\n",
    "#     'Current (mA)',\n",
    "#     'Power (mW)',\n",
    "    'Latitude (°)',\n",
    "    'Longitude (°)',\n",
    "    'GPS altitude (m)',\n",
    "    'GPS Horizontal Speed (km/h)',\n",
    "    'vehicle_heading',\n",
    "    'heading (radians)',\n",
    "#     'Distance to nearest road feature (°)',\n",
    "#     'Road Curvature (m radius)',\n",
    "#     'Road Grade (%)',\n",
    "#     'temperature (°C)',\n",
    "#     'Pressure (mbar)',\n",
    "#     'humidity (RH%)',\n",
    "    'Barometric Altitude (m)',\n",
    "    'Barometric Altitude Filtered (m)',\n",
    "    'Vertical Velocity (m/s)',\n",
    "#     'Pedal Rotation Speed (RPM)',\n",
    "#     'Motor Rotation Speed (RPM)',\n",
    "#     'filtered_motor_rpm',\n",
    "#     'acceleration X (m/s^2)',\n",
    "#     'acceleration Y (m/s^2)',\n",
    "#     'acceleration Z (m/s^2)',\n",
    "#     'Angular Velocity X (rad/s)',\n",
    "#     'Angular Velocity Y (rad/s)',\n",
    "#     'Angular Velocity Z (rad/s)',\n",
    "#     'Brake State',\n",
    "    'trip'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "def prep_pkl(file_path):\n",
    "    df = pd.read_pickle(file_path)\n",
    "    \n",
    "    drop_columns = [col for col in df if col not in final_table_columns]\n",
    "    \n",
    "    df.drop(columns=drop_columns, inplace=True)\n",
    "    return df\n",
    "\n",
    "pickle_files = [\n",
    "#     \"df_ml_hampsted.pkl\",\n",
    "#     \"df_ml_0.pkl\",\n",
    "#     \"df_ml_1.pkl\",\n",
    "#     \"df_ml_2.pkl\",\n",
    "    \"df_ml_putney_loop.pkl\"\n",
    "                ]\n",
    "\n",
    "dfs = [prep_pkl(i) for i in pickle_files]\n",
    "\n",
    "df_ml = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_test, df_ml_train = special_test_train_split(df_ml, test_size=0.1, random_state=24)\n",
    "del df_ml\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_test.loc[:,\"Test-Train\"] = \"Test\"\n",
    "df_ml_train.loc[:,\"Test-Train\"] = \"Train\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key datastats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seconds = 10\n",
    "def get_key_stats(df):\n",
    "    \n",
    "    key_stats = {}\n",
    "    \n",
    "    for i in df['trip'].unique():\n",
    "        trip_df = df[df['trip']==i]\n",
    "    \n",
    "        time_delta = trip_df['Datetime (UTC)'].diff().dt.total_seconds().fillna(0)    \n",
    "        total_ride_time = time_delta[time_delta < max_seconds].sum()/3600\n",
    "        \n",
    "        distance = get_horizontal_distance(trip_df)\n",
    "        distance = distance[distance<100].sum()/1000\n",
    "        \n",
    "        key_stats[i] = {\"Ride Time (hours)\": total_ride_time, \"Distance (km)\": distance}\n",
    "        \n",
    "    key_stats_df = pd.DataFrame.from_dict(key_stats, orient='index')\n",
    "    \n",
    "    print(\"Total Ride Time:{0} hours. Distance: {1} kilometers\".format(total_ride_time, distance))\n",
    "    \n",
    "    return key_stats_df\n",
    "\n",
    "key_stats_df = get_key_stats(df_ml_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(data=key_stats_df, x=\"Ride Time (hours)\")\n",
    "key_stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=key_stats_df, x='Distance (km)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_ml_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add SOC as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_soc_feature(df_ml_train, coulomb_counting)\n",
    "add_soc_feature(df_ml_test, coulomb_counting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display variables for initial viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all_variables(*raw_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display GPS variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_gps_positions(df_gps, lat_feature='Latitude (°)', long_feature='Longitude (°)'):\n",
    "    \"\"\"\n",
    "    Display GPS positions\n",
    "    \"\"\"\n",
    "    \n",
    "    df_gps = df_gps.sort_values(by='Datetime (UTC)')\n",
    "    # Display GPS positions\n",
    "    fig = px.line_mapbox(df_gps,\n",
    "                            lat=df_gps[lat_feature],\n",
    "                            lon=df_gps[long_feature],\n",
    "                            #color='Test Number',#'Test-Train',#\"GPS Horizontal Speed (km/h)\",#\"trip\",#\"slope\",#\"LOCATION Altitude ( m)\",,#\"Speed(km/h)\", # \"abs_acceleration\" or \"gps_acceleration\" or \"power\"\n",
    "                            zoom=14,\n",
    "                            hover_data=[#'Datetime (UTC)',\n",
    "                                        'GPS altitude (m)',\n",
    "                                        #\"sats\",\n",
    "                                        'heading (radians)'\n",
    "                            \n",
    "                            ],\n",
    "                         title=\"Training and Testing Routes in dataset\",\n",
    "                            #size=\"LOCATION Accuracy ( m)\"\n",
    "                           )\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "    #fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "\n",
    "    fig.write_html(\"output/GPS_track.html\")\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_into_n_minute_tests(test_length, row_timestep, df):\n",
    "    \"\"\"\n",
    "    test_length is length of test in seconds\n",
    "    row_timestep is timestep of each row\n",
    "    df is the dataframe to split into tests\n",
    "    \"\"\"\n",
    "    \n",
    "    test_n_rows = test_length/row_timestep\n",
    "    \n",
    "    tests = np.divmod(np.arange(len(df)),test_n_rows)[0]+1\n",
    "    print(tests)\n",
    "\n",
    "    df.loc[:, 'Test Number'] = tests\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_into_n_minute_tests(600, 0.01, df_ml_test)\n",
    "df_ml_train.loc[:, 'Test Number'] = 'Training'\n",
    "df_ml = pd.concat([df_ml_train, df_ml_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gps_positions(raw_dfs[1]) # df_gps is index 1 TODO: don't use indexes. use labels for readiblity\n",
    "# display_gps_positions(df_ml.sample(100000)) # df_gps is index 1 TODO: don't use indexes. use labels for readiblity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Display Charging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Ensure 1970 filter is removed, because the data is not timestamped\n",
    "df_ina = process_charge_data([raw_data_path+\"data_charge_14-5-21.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_ina_df(df_ina):\n",
    "    df_ina = df_ina.set_index('Datetime (UTC)')\n",
    "    df_ina = df_ina.resample('1S').mean()\n",
    "\n",
    "    display_charge_data(df_ina)\n",
    "\n",
    "df_ina_subset = df_ina.head(2500000)\n",
    "# Display charging profile\n",
    "resample_ina_df(df_ina_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlations_in_df(df_ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Generate a large random dataset\n",
    "rs = np.random.RandomState(33)\n",
    "d = df_ml_train[df_ml_train.columns.difference(['Barometric Altitude Filtered (m)','filtered_motor_rpm', 'vehicle_heading'])].sample(n=100000)\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = d.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show pairplots of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "features_to_pair_plot = [\n",
    "    'Voltage (V)',\n",
    "     'Current (mA)',\n",
    "   'Power (mW)',\n",
    "    'SOC',\n",
    "    #'heading (radians)',\n",
    "    'Barometric Altitude (m)',\n",
    "    #'Barometric Altitude Filtered (m)'\n",
    "    #'Pressure (mbar)',\n",
    "    \"temperature (°C)\",\n",
    "    'Pedal Rotation Speed (RPM)',\n",
    "    'Motor Rotation Speed (RPM)',\n",
    "    'Road Grade (%)'\n",
    "#     \"brake_state\",\n",
    "#     \"GPS Speed\",\n",
    "#     \"altitude\",\n",
    "#     \"gps_acceleration\"\n",
    "#     \"humidity (RH%)\"\n",
    "]\n",
    "\n",
    "battery_params = [\n",
    "    'Voltage (V)',\n",
    "    'Current (mA)',\n",
    "    'Power (mW)',\n",
    "    'SOC',\n",
    "    'temperature (°C)'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df = df_ml_train\n",
    "df = df[(df['Road Grade (%)'] > -10000) & (df['Road Grade (%)'] < 10000)]\n",
    "df = df[(df['Pedal Rotation Speed (RPM)'] > 0) & (df['Pedal Rotation Speed (RPM)'] < 100)]\n",
    "df = df[(df['Motor Rotation Speed (RPM)'] > 0) & (df['Motor Rotation Speed (RPM)'] < 45)]\n",
    "\n",
    "do_pair_plot(df, features_to_pair_plot, \"Pair Plot of E-bike parameters\",sample_size=30001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "do_pair_plot(df_ml_train, battery_params, \"Pair Plot of E-bike Battery parameters\", sample_size=40001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current (mA)',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime (UTC)',\n",
    "#  'INA226 ID',\n",
    "#  'Power (mW)',\n",
    "#  'Power Averaged (mW)',\n",
    "#  'Power_uncalibrated',\n",
    "#  'Shunt Voltage Drop (V)',\n",
    "#  'Voltage (V)',\n",
    " 'GPS Horizontal Speed (km/h)',\n",
    "    'Vertical Velocity (m/s)',\n",
    "#  'GPS altitude (m)',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'GPS Horizontal Acceleration (km/h^2)',\n",
    "#  'heading (radians)',\n",
    "#  'hour',\n",
    "#  'Latitude (°)',\n",
    "#  'Longitude (°)',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "#  'sats',\n",
    "#  'second',\n",
    "#  'Barometric Altitude (m)',\n",
    "#  'Pressure (mbar)',\n",
    "#  'Barometric Altitude Filtered (m)',\n",
    "#  'humidity (RH%)',\n",
    " 'Road Grade (%)',\n",
    "#  'temperature (°C)',\n",
    "#  'Pedal Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "#  'Motor Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_y',\n",
    "  'acceleration X (m/s^2)',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration Y (m/s^2)',\n",
    "#  'acceleration Z (m/s^2)',\n",
    "#  'Angular Velocity X (rad/s)',\n",
    "#   'gyro_x_filtered',\n",
    "  'Angular Velocity Y (rad/s)',\n",
    "#  'Angular Velocity Z (rad/s)',\n",
    "#  'Brake State',\n",
    "]\n",
    "do_pair_plot(df_ml_train, params_of_interest, \"Pair Plot of E-bike parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current (mA)',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime (UTC)',\n",
    "#  'INA226 ID',\n",
    "#  'Power (mW)',\n",
    "#  'Power Averaged (mW)',\n",
    "#  'Power_uncalibrated',\n",
    "#  'Shunt Voltage Drop (V)',\n",
    "#  'Voltage (V)',\n",
    " 'GPS Horizontal Speed (km/h)',\n",
    "    'Vertical Velocity (m/s)',\n",
    "#  'GPS altitude (m)',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'GPS Horizontal Acceleration (km/h^2)',\n",
    "#  'heading (radians)',\n",
    "#  'hour',\n",
    "#  'Latitude (°)',\n",
    "#  'Longitude (°)',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "#  'sats',\n",
    "#  'second',\n",
    "#  'Barometric Altitude (m)',\n",
    "#  'Pressure (mbar)',\n",
    "#  'Barometric Altitude Filtered (m)',\n",
    "#  'humidity (RH%)',\n",
    "#  'Road Grade (%)',\n",
    "#  'temperature (°C)',\n",
    "#  'Pedal Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "#  'Motor Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_y',\n",
    "  'acceleration X (m/s^2)',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration Y (m/s^2)',\n",
    "#  'acceleration Z (m/s^2)',\n",
    "#  'Angular Velocity X (rad/s)',\n",
    "#   'gyro_x_filtered',\n",
    "  'Angular Velocity Y (rad/s)',\n",
    "#  'Angular Velocity Z (rad/s)',\n",
    "#  'Brake State',\n",
    "]\n",
    "\n",
    "sns.relplot(\n",
    "    data=df_ml_train.sample(100000),\n",
    "    s=10,\n",
    "    x='GPS Horizontal Speed (km/h)', y='Power (mW)',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current (mA)',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime (UTC)',\n",
    "#  'INA226 ID',\n",
    "#  'Power (mW)',\n",
    "#  'Power Averaged (mW)',\n",
    "#  'Power_uncalibrated',\n",
    "#  'Shunt Voltage Drop (V)',\n",
    "#  'Voltage (V)',\n",
    " 'GPS Horizontal Speed (km/h)',\n",
    "#  'GPS altitude (m)',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'GPS Horizontal Acceleration (km/h^2)',\n",
    "#  'heading (radians)',\n",
    "#  'hour',\n",
    "#  'Latitude (°)',\n",
    "#  'Longitude (°)',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "#   'sats',\n",
    "#  'second',\n",
    "#  'Barometric Altitude (m)',\n",
    "#  'Pressure (mbar)',\n",
    "#  'Barometric Altitude Filtered (m)',\n",
    "#  'humidity (RH%)',\n",
    " 'Road Grade (%)',\n",
    "#  'temperature (°C)',\n",
    "#  'Pedal Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "  'Motor Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_y',\n",
    "#   'acceleration X (m/s^2)',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration Y (m/s^2)',\n",
    "#  'acceleration Z (m/s^2)',\n",
    "#  'Angular Velocity X (rad/s)',\n",
    "#   'gyro_x_filtered',\n",
    "#   'Angular Velocity Y (rad/s)',\n",
    "#  'Angular Velocity Z (rad/s)',\n",
    "#  'Brake State',\n",
    "#   'SOC'\n",
    "]\n",
    "do_pair_plot(df_ml_train, params_of_interest, \"Comparison of GPS Speed, Motor Internal Speed and GPS Sats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current (mA)',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime (UTC)',\n",
    "#  'INA226 ID',\n",
    "    'Power (mW)',\n",
    "#  'Power Averaged (mW)',\n",
    "#  'Power_uncalibrated',\n",
    "#  'Shunt Voltage Drop (V)',\n",
    "#  'Voltage (V)',\n",
    "  'GPS Horizontal Speed (km/h)',\n",
    "#  'GPS altitude (m)',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'GPS Horizontal Acceleration (km/h^2)',\n",
    "#  'heading (radians)',\n",
    "#  'hour',\n",
    "#  'Latitude (°)',\n",
    "#  'Longitude (°)',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "#   'sats',\n",
    "#  'second',\n",
    "#  'Barometric Altitude (m)',\n",
    "#  'Pressure (mbar)',\n",
    "#  'Barometric Altitude Filtered (m)',\n",
    "#  'humidity (RH%)',\n",
    "  'Road Grade (%)',\n",
    "#  'temperature (°C)',\n",
    "#  'Pedal Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "#   'Motor Rotation Speed (RPM)',\n",
    "#  'pulse_delay_us_y',\n",
    "#   'acceleration X (m/s^2)',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration Y (m/s^2)',\n",
    "#  'acceleration Z (m/s^2)',\n",
    "#  'Angular Velocity X (rad/s)',\n",
    "#   'gyro_x_filtered',\n",
    "#   'Angular Velocity Y (rad/s)',\n",
    "#  'Angular Velocity Z (rad/s)',\n",
    "#  'Brake State',\n",
    "#   'SOC'\n",
    "     'Vertical Velocity (m/s)',\n",
    "#     \"vertical_distance\"\n",
    "\n",
    "]\n",
    "%matplotlib inline\n",
    "\n",
    "df = df_ml_train\n",
    "\n",
    "df = df[(df['Road Grade (%)'] > -100000) & (df['Road Grade (%)'] < 100000)]\n",
    "df = df[(df['Vertical Velocity (m/s)'] > -0.25) & (df['Vertical Velocity (m/s)'] < 0.25)]\n",
    "df = df[(df['GPS Horizontal Speed (km/h)'] > -0.5) & (df['GPS Horizontal Speed (km/h)'] < 40)]\n",
    "\n",
    "\n",
    "do_pair_plot(df, params_of_interest, \"Comparison of Gravity parameters and Power\", sample_size=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_join_plot(df_ml_train, 'Vertical Velocity (m/s)', 'Power (mW)', \"vertical_velocity[m/s] vs Power output[mW] from Battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_join_plot(df_ml_train, \"vertical_distance\", 'Power (mW)', \"vertical_velocity[m/s] vs Power output[mW] from Battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_join_plot(df_ml_train, \"SOC\", 'Power (mW)', \"State-of-Charge(SOC) vs Power output[mW] from Battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "do_join_plot(df_ml, \"slope\", \"vertical_distance\", \"Vertical distance vs slope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export dataframe to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_pickle(df):\n",
    "    print(df.head())\n",
    "    df.to_pickle(\"df_ml_train.pkl\")\n",
    "\n",
    "export_to_pickle(df_ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display SOC vs power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.line(df_ml_train, x='SOC', y='Power (mW)', title='SOC vs Power')\n",
    "fig.update_xaxes(autorange=\"reversed\")\n",
    "fig.update_yaxes(title = \"Power[mW]\")\n",
    "fig.write_html(\"output/soc_vs_power.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display SOC vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.line(df_ml_test, x=df_ml_test['Datetime (UTC)'], y=\"SOC\", title='SOC over Time')\n",
    "fig.update_yaxes(title = \"Power[mW]\")\n",
    "fig.write_html(\"output/soc_vs_power.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display barometric altitude vs GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_barom_vs_gps(raw_dfs):\n",
    "\n",
    "    df_ina, df_gps, df_baro, df_pas, df_ms, df_imu, df_brake = raw_dfs\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                       )\n",
    "\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_baro['Datetime (UTC)'],\n",
    "        y=df_baro[\"Barometric_Altitude_Uncalibrated\"],\n",
    "        name=\"Barometric Altitude Uncalibrated\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_baro['Datetime (UTC)'],\n",
    "        y=df_baro[\"Baro_Altitude\"],\n",
    "        name=\"Barometric Altitude Calibrated\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_baro['Datetime (UTC)'],\n",
    "        y=df_gps[\"altitude\"],\n",
    "        name=\"GPS Altitude\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Altitude[m]\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"GPS Altitude vs Barometric Altitude\")\n",
    "\n",
    "    fig.write_html(\"output/GPS_vs_Baro.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "display_barom_vs_gps(raw_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ina(raw_dfs):\n",
    "\n",
    "    df_ina, df_gps, df_baro, df_pas, df_ms, df_imu, df_brake = raw_dfs\n",
    "    \n",
    "    #df_ina = df_ina.sample(n=100000).sort_values('Datetime (UTC)')\n",
    "    df_ina = df_ina.iloc[-100000:]\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                       )\n",
    "\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_ina['Datetime (UTC)'],\n",
    "        y=df_ina['Power (mW)'],\n",
    "        name='Power (mW)',\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_ina['Datetime (UTC)'],\n",
    "        y=df_ina[\"Power_averaged\"],\n",
    "        name=\"Power Averaged\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.write_html(\"output/ina.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "display_ina(raw_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 3D plot of trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_plot(raw_dfs[1], raw_dfs[2], raw_dfs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group power into grid squares of longitude/latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data_location(df):\n",
    "    step = 0.0002\n",
    "    to_bin = lambda x: np.floor(x / step) * step\n",
    "    df['Latitude (°)'] = df['Latitude (°)'].map(to_bin)\n",
    "    df['Longitude (°)'] = df['Longitude (°)'].map(to_bin)\n",
    "    \n",
    "    \n",
    "#     step = 0.1\n",
    "#     to_bin = lambda x: np.floor(x / step) * step\n",
    "#     df[\"headingbin\"] = df['heading (radians)'].map(to_bin)\n",
    "    \n",
    "    groups = df.groupby([\n",
    "        \"Latitude (°)\", \n",
    "        'Longitude (°)',\n",
    "#         'headingbin'\n",
    "    ]).mean().reset_index()\n",
    "    \n",
    "    \n",
    "    \n",
    "    return groups\n",
    "\n",
    "def group_data_time_interval(df):\n",
    "    groups = df.groupby(pd.Grouper(key='Datetime (UTC)', freq=\"1s\")).mean()\n",
    "    #df['Datetime (UTC)'] = df.index\n",
    "    groups = groups.dropna()\n",
    "    return groups\n",
    "\n",
    "# df_ml_train_grouped = group_data_time_interval(df_ml_train)\n",
    "# display_gps_positions_bins(df_ml_train_grouped)\n",
    "df_ml_test_grouped = group_data_location(df_ml_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_test_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gps_positions(df_ml_test_grouped, lat_feature='Latitude (°)', long_feature='Longitude (°)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display distribution of power parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(raw_dfs_train[0], x='Power (mW)', title='Power Distribution')\n",
    "fig.update_xaxes(title_text=\"Power[mW]\")\n",
    "fig.show()\n",
    "fig = px.histogram(raw_dfs_train[0], x='Voltage (V)', title='Battery Voltage Distribution')\n",
    "fig.update_xaxes(title_text=\"Voltage[V]\")\n",
    "fig.show()\n",
    "fig = px.histogram(raw_dfs_train[0], x=\"Current\", title='Current Distribution')\n",
    "fig.update_xaxes(title_text=\"Current[mA]\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display speed vs power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.line(raw_dfs_train[4], x='Datetime (UTC)', y=\"filtered_motor_rpm\", title='Speed vs Time').show()\n",
    "fig =  px.line(raw_dfs_train[4], x='Datetime (UTC)', y=\"motor_rpm\", title='Speed vs Time').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Lat/Long vs power(unbinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "#latitude_start_pt, longitude_start_pt = 51.45282, -0.2275045\n",
    "from scipy.signal import find_peaks\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "L1 = [51.45282, -0.2275045]\n",
    "def plot_proximity_to_start_point(df):\n",
    "    df['distance'] = df[['Latitude (°)', 'Longitude (°)']].sub(np.array(L1)).pow(2).sum(1).pow(0.5)\n",
    "    \n",
    "    fig = px.line(df, x='Datetime (UTC)', y=\"distance\", title='Distance from start point').show()\n",
    "    \n",
    "    time_series = df['distance']\n",
    "    indices = find_peaks(-time_series, distance = 2000,height=-0.0005)[0]\n",
    "    \n",
    "    \n",
    "    df['Loop number'] = 0\n",
    "    for i in range(len(indices)-1):\n",
    "        rows = range(indices[i],indices[i+1])\n",
    "        \n",
    "        df.loc[rows, 'Loop number'] = i+1\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "plot_proximity_to_start_point(df_ml_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_on_each_loop(df):\n",
    "    df = df.sample(frac=0.1)\n",
    "    unique_loops = sorted(df['Loop number'].unique())\n",
    "    # Group data together\n",
    "    hist_data = [df[df['Loop number']==i]['Power (mW)'] for i in unique_loops]\n",
    "\n",
    "    group_labels = [\"Lap \"+str(i) for i in unique_loops]\n",
    "\n",
    "    # Create distplot with custom bin_size\n",
    "    fig = ff.create_distplot(hist_data, group_labels, bin_size=10000)\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Distribution of Power values, over the course of 12 laps\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "    fig.update_xaxes(title=\"Power (mW)\")\n",
    "    fig.update_yaxes(title=\"Fraction of power values\")\n",
    "    fig.write_html(\"output/Distribution-of-power-values-each-lap.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_distribution_on_each_loop(df_ml_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "import numpy as np\n",
    "\n",
    "def plot_params_on_each_loop(df):\n",
    "    \n",
    "    \n",
    "    df['Power (mW) Filtered'] =  df.rolling(window=100)['Power (mW)'].mean().fillna(0)\n",
    "    \n",
    "    \n",
    "    target_loop_n = 3\n",
    "    \n",
    "\n",
    "    X = df[df['Loop number']==target_loop_n][['Latitude (°)', 'Longitude (°)']]\n",
    "    kdt = KDTree(X, leaf_size=30, metric='euclidean')\n",
    "    indexes = kdt.query(df[['Latitude (°)', 'Longitude (°)']], k=1, return_distance=False)\n",
    "    \n",
    "    df[\"Trip Progress (%)\"] = 100 * (indexes - indexes.min())/(indexes.max() - indexes.min())\n",
    "    \n",
    "    \n",
    "    df_list = []\n",
    "    for i in df['Loop number'].unique():\n",
    "        df_list.append(df[df['Loop number'] == i].drop_duplicates(subset=['Trip Progress (%)']))\n",
    "   \n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    df.sort_values(by=['Loop number','Trip Progress (%)'], inplace=True)\n",
    "\n",
    "\n",
    "    fig = go.Figure()\n",
    "\n",
    "    \n",
    "    for i in df['Loop number'].unique():        \n",
    "        fig.add_trace(go.Scatter(x=df[df['Loop number'] == i]['Trip Progress (%)'],\n",
    "                                 y=df[df['Loop number'] == i]['Power (mW) Filtered'],\n",
    "                                 fill='tozeroy',\n",
    "                                 name = 'Lap {0}'.format(i)\n",
    "                                )\n",
    "                     ) # fill down to xaxis\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Power profile(low pass filtered) on each loop\",\n",
    "    )\n",
    "    \n",
    "    fig.update_xaxes(title=\"Lap Progress (%)\")\n",
    "    fig.update_yaxes(title=\"Power (mW)\")\n",
    "\n",
    "\n",
    "    \n",
    "    fig.write_html(\"output/Power_profile_on_each_loop.html\")\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "\n",
    "\n",
    "plot_params_on_each_loop(df_ml_train.dropna().sort_values(by='Datetime (UTC)'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Energy Consumption each loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_consumption_for_each_loop(df_ml):\n",
    "    energies_per_loop = []\n",
    "    for i in df_ml['Loop number'].unique():\n",
    "        \n",
    "        df_loop = df_ml[df_ml[\"Loop number\"] == i]\n",
    "        energy_in_loop = energy_from_power_time(df_loop['Datetime (UTC)'], df_loop['Power (mW)'])\n",
    "        energies_per_loop.append((i,energy_in_loop))\n",
    "                                 \n",
    "    return pd.DataFrame(energies_per_loop, columns=['Loop number', 'Energy Per Loop (kJ)'])\n",
    "\n",
    "def plot_energy_consumption_per_loop(df_ml):\n",
    "    energies_per_loop = calculate_energy_consumption_for_each_loop(df_ml)       \n",
    "    fig = px.line(energies_per_loop, x='Loop number', y='Energy Per Loop (kJ)', title='Energy consumption of each loop around Putney Heath')\n",
    "    fig.update_layout(yaxis_range=[48,65])\n",
    "    \n",
    "    fig.update_layout(\n",
    "        xaxis = dict(\n",
    "            tickmode = 'linear',\n",
    "            tick0 = 1,\n",
    "            dtick = 1\n",
    "        )\n",
    "    )\n",
    "    fig.write_html(\"output/Energy_consumption_per_loop.html\")\n",
    "    fig.show()\n",
    "\n",
    "plot_energy_consumption_per_loop(df_ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Lat/Long vs power(binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proximity_to_start_point_binned(df):\n",
    "    df['distance'] = df[['Latitude (°)', 'Longitude (°)']].sub(np.array(L1)).pow(2).sum(1).pow(0.5)\n",
    "    \n",
    "    \n",
    "    time_series = df['distance']\n",
    "    indices = find_peaks(-time_series,\n",
    "                         distance = 2000,\n",
    "                         height=-0.0005)[0]\n",
    "    \n",
    "    \n",
    "    df[\"ts\"] = df.index.values\n",
    "    df['Loop number'] = 0\n",
    "    for i in range(len(indices)-1):\n",
    "        \n",
    "        start_time = df[\"ts\"].iloc[indices[i]]\n",
    "        end_time = df[\"ts\"].iloc[indices[i+1]]        \n",
    "        df.loc[start_time:end_time, 'Loop number'] = i+1\n",
    "    \n",
    "    fig = px.line(df, x='Latitude (°)', y='Power (mW)', color='Loop number', title= \"Power profile on each loop\")\n",
    "    fig.write_html(\"output/Power_profile_on_each_loop_binned.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_proximity_to_start_point_binned(df_ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.scatter(df_ml_train, x=\"Latitude (°)\", y=\"Power\", title='Latitude vs Power').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_imu_plots(df_imu):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=df_imu[\"gyro_x\"],\n",
    "                             y=df_imu[\"acceleration_x\"],\n",
    "                             mode='markers',\n",
    "                             marker=dict(size=1),\n",
    "                             name='Raw data'\n",
    "                            )\n",
    "                 )\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df_imu[\"gyro_x_filtered\"], \n",
    "                             y=df_imu[\"acceleration_x_filtered\"],\n",
    "                             mode='markers',\n",
    "                             marker=dict(size=1),\n",
    "                             name='Filtered data'\n",
    "\n",
    "                            )\n",
    "                 )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"IMU Acceleration vs Angular velocity(gyro)\",\n",
    "        xaxis_title=\"Angular Velocity[rad/s]\",\n",
    "        yaxis_title=\"Acceleration[m/s^2]\",\n",
    "    )\n",
    "    fig.show()\n",
    "                  \n",
    "display_imu_plots(raw_dfs_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(raw_dfs_train[5], x=\"gyro_x\", y=\"acceleration_x\", title='Acceleration[m/s^2] vs Angular velocity[rad/s]')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(raw_dfs_train[5], x='Datetime (UTC)', y=[\"acceleration_x\",\"acceleration_x_filtered\"], title='Acceleration over Time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_ml_train, x='Datetime (UTC)', y=[\"Power\",\"Power_averaged\"], title='Power over Time').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML model XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_data(timestamps, ytest, ypred, scores, show_html=False, save_image=True):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_traces(go.Scatter(x=timestamps, y=ytest, name='Actual data'))\n",
    "    fig.add_traces(go.Scatter(x=timestamps, y=ypred, name='Regression Fit'))\n",
    "    \n",
    "    title = \"Power consumption, Actual and Predicted.<br>Predicted Energy consumption:{0:.2f} kJ, Actual Energy consumption:{1:.2f} kJ,<br>Trip Prediction Error:{2:.1f} % RMSE Score:{3:.0f} W\".format(scores[\"predicted\"],\n",
    "                                                                                                                                              scores[\"actual\"],\n",
    "                                                                                                                                              scores[\"percentage_error\"],\n",
    "                                                                                                                                              scores[\"RMSE score\"]/1000\n",
    "\n",
    "                                                                                                                                             )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Time(UTC)\",\n",
    "        yaxis_title=\"Power[mW]\",\n",
    "    )\n",
    "    fig.write_html(\"output/Predicted_plot.html\")\n",
    "    \n",
    "    if save_image:\n",
    "        ts = timestamps.iloc[0]\n",
    "        print(ts)\n",
    "        fig.write_image(\"output/images/predictions_on_{0}.jpeg\".format(ts),scale=4, width=1600, height=900)\n",
    "\n",
    "        \n",
    "    if show_html:\n",
    "        fig.show()\n",
    "        \n",
    "def split_into_test_runs(test_length, row_timestep, df_ml_test):\n",
    "    test_n_rows = test_length/row_timestep\n",
    "\n",
    "    n_rows = len(df_ml_test.index)\n",
    "\n",
    "    tests = np.array_split(df_ml_test, n_rows//test_n_rows)\n",
    "    \n",
    "    return tests\n",
    "\n",
    "def test_short_runs(xgbr, df_ml_test, predictor, scaler = None, test_length = 600, row_timestep = 0.01, show_plots=False, predictor_args=None):\n",
    "\n",
    "    tests = split_into_test_runs(test_length, row_timestep, df_ml_test);\n",
    "    \n",
    "    scores = []\n",
    "    for test in tests:\n",
    "        error = predictor(xgbr, test, plot=show_plots, predictor_args=predictor_args)\n",
    "        scores.append(error)\n",
    "        \n",
    "    return pd.Series(scores)\n",
    "\n",
    "\n",
    "def print_power_consumption_score(timestamps, ytest, ypred):\n",
    "    actual_energy = energy_from_power_time(timestamps, ytest)\n",
    "    predicted_energy = energy_from_power_time(timestamps, ypred)\n",
    "    error = get_energy_error(predicted_energy, actual_energy)\n",
    "    \n",
    "    return error, actual_energy, predicted_energy\n",
    "\n",
    "def score_predicted_data(model, df_ml_test, scalar=None, predictor_args=None):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    \n",
    "    if scalar:\n",
    "        x = scaler.transform(x)\n",
    "        \n",
    "\n",
    "    if predictor_args:\n",
    "        ypred = model.predict(x, *predictor_args).flatten()\n",
    "    else:\n",
    "        ypred = model.predict(x).flatten()\n",
    "        \n",
    "    ypred=ypred.clip(min=0)\n",
    "\n",
    "    \n",
    "    rmse = mean_squared_error(y, ypred, squared=False)\n",
    "    \n",
    "    a = y - ypred\n",
    "    abs_error = a.abs()\n",
    "    \n",
    "    error, actual_energy, predicted_energy = print_power_consumption_score(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    \n",
    "    print(\"Actual energy:\",actual_energy, \"Predicted Energy:\", predicted_energy, \"Error[%](ideal should be 0%):\", error, \"% \", \"RMSE Score: {:,}\".format(rmse) )\n",
    "\n",
    "    return y, ypred, error, actual_energy, predicted_energy, rmse, abs_error\n",
    "\n",
    "def make_predictions(model, df_ml_test, scalar=None, plot=True, predictor_args=None):\n",
    "    y, ypred, error, actual_energy, predicted_energy, rmse, abs_error = score_predicted_data(model, df_ml_test, scalar=scalar, predictor_args=predictor_args)\n",
    "    \n",
    "    scores = {\"predicted\":predicted_energy,\"actual\":actual_energy,\"percentage_error\":error, \"RMSE score\": rmse}\n",
    "    if plot == True:\n",
    "        plot_predicted_data(df_ml_test['Datetime (UTC)'], y, ypred, scores)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USE XGBOOST predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "def do_ml(x,y):\n",
    "    parmas = {'max_depth': 12, \n",
    "              'learning_rate': 0.04823939007347505, \n",
    "              'colsample_bytree': 0.2577650725393863,\n",
    "              'subsample': 0.4278423362185552, \n",
    "              'alpha': 0.05460670834513764, \n",
    "              'lambda': 0.01647475526883333,\n",
    "              'min_child_weight': 24.82354496640231,\n",
    "              'verbosity':2,\n",
    "              'tree_method':'gpu_hist',\n",
    "              'gpu_id':0,\n",
    "              'n_estimators':200\n",
    "             }\n",
    "\n",
    "    xgbr = xgb.XGBRegressor(**parmas)\n",
    "    print(xgbr)\n",
    "    \n",
    "    xgbr.fit(x, y)\n",
    "    \n",
    "\n",
    "    print(\"Training score R2: \", xgbr.score(x, y))\n",
    "    \n",
    "\n",
    "    _ = plot_importance(xgbr, height=0.9)\n",
    "    \n",
    "    return xgbr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "X, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "\n",
    "xgbr = do_ml(X, y)\n",
    "xgbr.save_model('xgbr_model_offline_only_hyper_optimised.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr = xgb.XGBRegressor()\n",
    "xgbr.load_model('xgbr_model_offline_only.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test of 15 minute runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = test_short_runs(xgbr, df_ml_test.sample(frac=frac).sort_values(by='Datetime (UTC)'), make_predictions, test_length = 60 * 30, row_timestep = 0.01/frac, show_plots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = scores[(scores > -1000) & (scores < 1000)] \n",
    "\n",
    "sns.displot(x=scores, kde=True)\n",
    "pd.DataFrame(scores).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_scores_for_range_of_trip_lengths(time_lengths):\n",
    "    \n",
    "    scores_list = []\n",
    "\n",
    "    for duration in time_lengths:\n",
    "        scores = test_short_runs(xgbr, \n",
    "                                 df_ml_test.sample(frac=frac).sort_values(by='Datetime (UTC)'),\n",
    "                                 make_predictions,\n",
    "                                 test_length = 60 * duration, \n",
    "                                 row_timestep = 0.01/frac,\n",
    "                                 show_plots=False)\n",
    "        \n",
    "        scores = scores[(scores > -1000) & (scores < 1000)] \n",
    "\n",
    "        for i in scores:\n",
    "            scores_list.append({\"Trip Duration (minutes)\": duration, \"Trip Error (%)\": i })\n",
    "            \n",
    "        \n",
    "    return pd.DataFrame(scores_list)\n",
    "\n",
    "\n",
    "scores_df = get_scores_for_range_of_trip_lengths(range(5,30,5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "sns.displot(scores_df,\n",
    "            x=\"Trip Error (%)\",\n",
    "            hue=\"Trip Duration (minutes)\",\n",
    "            stat=\"density\",\n",
    "            common_norm=False,\n",
    "            palette=\"tab10\",\n",
    "#             kind=\"kde\", \n",
    "#             multiple=\"stack\"\n",
    "           )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot RMSE under different conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "y, ypred, error, actual_energy, predicted_energy, rmse, abs_error= score_predicted_data(xgbr, df_ml_test, scalar=None, predictor_args=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_test.loc[:,'Absolute Error Power Prediction (mW)'] = abs_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "\n",
    "g = sns.jointplot(x=\"SOC\", y='Absolute Error Power Prediction (mW)', data=df_ml_test.sample(10000),\n",
    "                  kind=\"reg\",\n",
    "                  truncate=False,\n",
    "                  color=\"m\",\n",
    "                  height=7,\n",
    "                  scatter_kws={'s': 2}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "g = sns.jointplot(x='GPS Horizontal Speed (km/h)', y='Absolute Error Power Prediction (mW)', data=df_ml_test.sample(10000),\n",
    "                  kind=\"reg\",\n",
    "                  truncate=False,\n",
    "                  color=\"m\",\n",
    "                  height=7,\n",
    "                  scatter_kws={'s': 2}\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimise with Optuna\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from optuna import create_study\n",
    "from optuna.samplers import TPESampler\n",
    "from optuna.integration import XGBoostPruningCallback\n",
    "\n",
    "FS = (14, 6)  # figure size\n",
    "RS = 124  # random state\n",
    "N_JOBS = 8  # number of parallel threads\n",
    "\n",
    "# repeated K-folds\n",
    "N_SPLITS = 10\n",
    "N_REPEATS = 1\n",
    "\n",
    "# Optuna\n",
    "N_TRIALS = 100\n",
    "MULTIVARIATE = True\n",
    "\n",
    "# XGBoost\n",
    "EARLY_STOPPING_ROUNDS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, random_state=22, n_splits=3, n_repeats=2, n_jobs=1, early_stopping_rounds=50,):\n",
    "    # XGBoost parameters\n",
    "    params = {\n",
    "        \"tree_method\":'gpu_hist',\n",
    "        \"gpu_id\": 0,\n",
    "        \"verbosity\": 2,  # 0 (silent) - 3 (debug)\n",
    "        \"objective\": \"reg:squarederror\",\n",
    "        \"n_estimators\": 500,\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 4, 12),\n",
    "        \"learning_rate\": trial.suggest_loguniform(\"learning_rate\", 0.005, 0.05),\n",
    "        \"colsample_bytree\": trial.suggest_loguniform(\"colsample_bytree\", 0.2, 0.6),\n",
    "        \"subsample\": trial.suggest_loguniform(\"subsample\", 0.4, 0.8),\n",
    "        \"alpha\": trial.suggest_loguniform(\"alpha\", 0.01, 10.0),\n",
    "        \"lambda\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n",
    "        \"gamma\": trial.suggest_loguniform(\"lambda\", 1e-8, 10.0),\n",
    "        \"min_child_weight\": trial.suggest_loguniform(\"min_child_weight\", 10, 1000),\n",
    "        \"seed\": random_state,\n",
    "        \"n_jobs\": n_jobs,\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params)\n",
    "    pruning_callback = XGBoostPruningCallback(trial, \"validation_0-rmse\")\n",
    "    rkf = RepeatedKFold(\n",
    "        n_splits=n_splits, n_repeats=n_repeats, random_state=random_state\n",
    "    )\n",
    "    X_values = X.values\n",
    "    y_values = y.values\n",
    "    y_pred = np.zeros_like(y_values)\n",
    "    for train_index, test_index in rkf.split(X_values):\n",
    "        X_A, X_B = X_values[train_index, :], X_values[test_index, :]\n",
    "        y_A, y_B = y_values[train_index], y_values[test_index]\n",
    "        model.fit(\n",
    "            X_A,\n",
    "            y_A,\n",
    "            eval_set=[(X_B, y_B)],\n",
    "            eval_metric=\"rmse\",\n",
    "            verbose=0,\n",
    "            callbacks=[pruning_callback],\n",
    "            early_stopping_rounds=early_stopping_rounds,\n",
    "        )\n",
    "        y_pred[test_index] += model.predict(X_B)\n",
    "    y_pred /= n_repeats\n",
    "    return np.sqrt(mean_squared_error(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = TPESampler(seed=RS, multivariate=MULTIVARIATE)\n",
    "study = create_study(direction=\"minimize\", sampler=sampler)\n",
    "study.optimize(\n",
    "    lambda trial: objective(\n",
    "        trial,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        random_state=RS,\n",
    "        n_splits=N_SPLITS,\n",
    "        n_repeats=N_REPEATS,\n",
    "        n_jobs=8,\n",
    "        early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n",
    "    ),\n",
    "    n_trials=N_TRIALS,\n",
    "    n_jobs=1,\n",
    ")\n",
    "\n",
    "# display params\n",
    "hp = study.best_params\n",
    "for key, value in hp.items():\n",
    "    print(f\"{key:>20s} : {value}\")\n",
    "print(f\"{'best objective value':>20s} : {study.best_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display interesting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_interesting_variables(df_ml_test, xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Neural Network with Structured data input to do regression\n",
    "Currently, we pass rows into the XG boost model. What if we could insert a snap shot of 10 seconds of data containing all the features, and calculating the energy consumption of this snapshot? Its like a photograph used in Deep Neural Networks: 2 dimensional input. Run the StructuredDataRegressor.\n",
    "You can also leave the epochs unspecified for an adaptive number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nFEzlsEZaz1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the structured data regressor.\n",
    "reg = ak.StructuredDataRegressor(\n",
    "    #overwrite=True,\n",
    "    max_trials=1\n",
    ")  # It tries 3 different models.\n",
    "\n",
    "\n",
    "\n",
    "df_ml_train.dropna(subset=params_x_for_ml, inplace=True)\n",
    "x, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "# Feed the structured data regressor with training data.\n",
    "with tf.device('/gpu:0'):\n",
    "    reg.fit(x,\n",
    "            y,\n",
    "            epochs=2\n",
    "           )\n",
    "\n",
    "model = reg.export_model()\n",
    "\n",
    "print(type(model))  # <class 'tensorflow.python.keras.engine.training.Model'>\n",
    "\n",
    "try:\n",
    "    model.save(\"model_autokeras\", save_format=\"tf\")\n",
    "except Exception:\n",
    "    model.save(\"model_autokeras.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_predicted_data_autokeras(model, df_ml_test,scaler):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    x = scaler.transform(x)\n",
    "    ypred = model.predict(x).flatten()    \n",
    "\n",
    "    print_power_consumption_score(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    plot_predicted_data(df_ml_test['Datetime (UTC)'], y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_predicted_data_autokeras(reg, df_ml_test.loc[:1e6], scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def score_predicted_data(model, df_ml_test, scalar=None):\n",
    "        \n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    \n",
    "    if scalar:\n",
    "        x = scaler.transform(x)\n",
    "        \n",
    "    ypred = model.predict(x).flatten()\n",
    "    r2_score = model.score(y, ypred)\n",
    "    error, actual_energy, predicted_energy = print_power_consumption_score(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    return y, ypred, error\n",
    "\n",
    "def make_predictions_keras_structured(model, df_ml_test, scalar=None, plot=True):\n",
    "    y, ypred, error, r2_score = score_predicted_data(model, df_ml_test, scalar)\n",
    "    if plot == True:\n",
    "        plot_predicted_data(df_ml_test['Datetime (UTC)'], y, ypred, r2_score)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = test_short_runs(reg, df_ml_test, make_predictions_keras_structured, test_length = 60 * 10, row_timestep = 0.01, show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.displot(x=scores, kde=True)\n",
    "pd.DataFrame(scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Scikit learn simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_ml_train.dropna(subset=params_x_for_ml, inplace=True)\n",
    "x, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "#reg = svm.SVR().fit(x, y)\n",
    "reg = LinearRegression().fit(x, y)\n",
    "print(\"Score: \",reg.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_predicted_data_autokeras(reg, df_ml_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def score_predicted_data_sk(model, df_ml_test):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    x = scaler.transform(x)\n",
    "    ypred = model.predict(x)\n",
    "    error, actual_energy, predicted_energy = print_power_consumption_score(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    return y, ypred, error\n",
    "\n",
    "def make_predictions_sk(model, df_ml_test, plot=True):\n",
    "    y, ypred, error = score_predicted_data_sk(model, df_ml_test)\n",
    "    if plot == True:\n",
    "        plot_predicted_data(df_ml_test['Datetime (UTC)'], y, ypred)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = test_short_runs(reg, df_ml_test, make_predictions_sk, test_length = 5*60, row_timestep = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = np.clip(scores, -100, 100 )\n",
    "sns.displot(x=scores, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Light BGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import optuna\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold, train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def objective(trial, data=df_ml_train[params_x_for_ml], target=df_ml_train[params_y_for_ml]):\n",
    "    \n",
    "    train_x, test_x, train_y, test_y = train_test_split(data, target, test_size=0.2,random_state=42)\n",
    "    param = {\n",
    "        #'metric': ['l2', 'auc'],\n",
    "        'random_state': 48,\n",
    "        'n_estimators': 100,\n",
    "        'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n",
    "        'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n",
    "        'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3,0.4,0.5,0.6,0.7,0.8,0.9, 1.0]),\n",
    "        'subsample': trial.suggest_categorical('subsample', [0.4,0.5,0.6,0.7,0.8,1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.006,0.008,0.01,0.014,0.017,0.02]),\n",
    "        'max_depth': trial.suggest_categorical('max_depth', [10,20,100]),\n",
    "        'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n",
    "        'min_data_per_group' : trial.suggest_int('min_data_per_group', 1, 100),\n",
    "        'verbose': 0,\n",
    "\n",
    "\n",
    "    }\n",
    "    model = LGBMRegressor(**param)  \n",
    "    \n",
    "    model.fit(train_x,train_y,eval_set=[(test_x,test_y)],early_stopping_rounds=100,verbose=False)\n",
    "    \n",
    "    preds = model.predict(test_x)\n",
    "    \n",
    "    rmse = mean_squared_error(test_y, preds,squared=False)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "print('Number of finished trials:', len(study.trials))\n",
    "print('Best trial:', study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_optimization_histor: shows the scores from all trials as well as the best score so far at each point.\n",
    "optuna.visualization.plot_optimization_history(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_parallel_coordinate: interactively visualizes the hyperparameters and scores\n",
    "optuna.visualization.plot_parallel_coordinate(study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "plot_slice: shows the evolution of the search. You can see where in the hyperparameter space your search\n",
    "went and which parts of the space were explored more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "optuna.visualization.plot_slice(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#plot_contour: plots parameter interactions on an interactive chart. You can choose which hyperparameters you would like to explore.\n",
    "optuna.visualization.plot_contour(study, params=['num_leaves',\n",
    "                            'max_depth',\n",
    "                            'subsample',\n",
    "                            'learning_rate',\n",
    "                            'subsample'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize parameter importances.\n",
    "optuna.visualization.plot_param_importances(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Visualize empirical distribution function\n",
    "optuna.visualization.plot_edf(study)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "gbm = LGBMRegressor(**study.best_params)\n",
    "scores = cross_val_score(gbm, X_train, y_train, cv=3)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run single training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyper_params = {\n",
    "#     'task': 'train',\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective': 'regression',\n",
    "#     #'metric': ['l2', 'auc'],\n",
    "#     'learning_rate': 0.005,\n",
    "#     'feature_fraction': 0.9,\n",
    "#     'bagging_fraction': 0.7,\n",
    "#     'bagging_freq': 10,\n",
    "#     'verbose': 0,\n",
    "#     \"max_depth\": 8,\n",
    "#     \"num_leaves\": 128,  \n",
    "#     \"max_bin\": 512,\n",
    "#     \"num_iterations\": 100000,\n",
    "    \"n_estimators\": 1000\n",
    "}\n",
    "\n",
    "params = study.best_params\n",
    "params[\"n_estimators\"] = 1000\n",
    "\n",
    "gbm = lgb.LGBMRegressor(**hyper_params)\n",
    "#gbm = lgb.LGBMRegressor(**params)\n",
    "\n",
    "print(gbm)\n",
    "\n",
    "\n",
    "gbm.fit(*split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml),\n",
    "        eval_set=[split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)],\n",
    "       )\n",
    "\n",
    "\n",
    "\n",
    "print(\"Training score R2: \", gbm.score(*split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)))\n",
    "\n",
    "lgb.plot_importance(gbm, height=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = test_short_runs(gbm, df_ml_test, make_predictions, test_length = 60 * 10, row_timestep = 0.01, show_plots=False, predictor_args=gbm.best_iteration_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = scores[(scores > -1000) & (scores < 1000)] \n",
    "\n",
    "\n",
    "sns.displot(x=scores, kde=True)\n",
    "pd.DataFrame(scores).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try to use the ImageRegression for autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5HmCvDu2EtQ"
   },
   "source": [
    "To make this tutorial easy to follow, we just treat MNIST dataset as a\n",
    "regression dataset. It means we will treat prediction targets of MNIST dataset,\n",
    "which are integers ranging from 0 to 9 as numerical values, so that they can be\n",
    "directly used as the regression targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prep_for_autokeras_image_regressor(df_ml):\n",
    "    \n",
    "    chunks = np.array_split(\n",
    "        df_ml[params_x_for_ml+[params_y_for_ml]].to_numpy(),\n",
    "        range(0, len(df_ml), 100) # 100 x 0.01 seconds chunks = 1 second chunks\n",
    "    )\n",
    "\n",
    "    chunks = chunks[1:-1] # Drop the first and last chunk that may be shorter\n",
    "\n",
    "    energies = []\n",
    "    chunks_edited = []\n",
    "\n",
    "    time_interval = 0.010 # seconds\n",
    "    for chunk in chunks:\n",
    "        powers = chunk[:, -1] # for last column in mW\n",
    "        energy = np.sum(powers * time_interval / 1000000) # in KiloJoules\n",
    "        chunks_edited.append(chunk[:, :-1]) # for all but last column\n",
    "        energies.append(energy)\n",
    "\n",
    "    \n",
    "    fig =  px.line(y=energies, title='Energies islotated').show()\n",
    "\n",
    "\n",
    "\n",
    "    y = np.array(energies)\n",
    "    x = np.array(chunks_edited)\n",
    "\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_ml_image_regression(x, y):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)\n",
    "\n",
    "    # Initialize the image regressor.\n",
    "    reg = ak.ImageRegressor(overwrite=True,\n",
    "                            max_trials=3\n",
    "                           )\n",
    "    # Feed the image regressor with training data.\n",
    "    reg.fit(x, y)\n",
    "\n",
    "    # Evaluate the best model with testing data.\n",
    "    #print(reg.evaluate(X_test, y_test))\n",
    "    \n",
    "    return reg\n",
    "\n",
    "reg  = do_ml_image_regression(*prep_for_autokeras_image_regressor(df_ml_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Predict with the best model.\n",
    "\n",
    "def predict_and_score(reg, df_ml_test):\n",
    "    x, y  = prep_for_autokeras_image_regressor(df_ml_test)\n",
    "    predicted_y = reg.predict(x)\n",
    "\n",
    "    fig =  px.line(y=predicted_y.flatten().tolist(), title='predicted_y').show()\n",
    "\n",
    "\n",
    "    length = len(y)\n",
    "\n",
    "    # intialise data of lists.\n",
    "    data = {'Energies':predicted_y.flatten().tolist() + y.tolist(),\n",
    "            'type_of_data':length * [\"Predicted\"] + length * [\"Actual\"],\n",
    "            \"Index\": list(range(length))*2}\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print the output.\n",
    "    fig = px.line(df, x = \"Index\", y=\"Energies\", color=\"type_of_data\", title='Energies').show()\n",
    "\n",
    "    get_energy_error(sum(predicted_y), sum(y))\n",
    "    \n",
    "predict_and_score(reg, df_ml_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters",
   "language": "python",
   "name": "masters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
