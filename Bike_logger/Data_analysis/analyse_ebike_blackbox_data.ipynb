{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse data from ebike datalogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip3 install autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import autokeras as ak\n",
    "import gc\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance, plot_tree, to_graphviz\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "import glob \n",
    "import os\n",
    "import scipy as sp\n",
    "import scipy.signal as sg\n",
    "\n",
    "\n",
    "from butter_filter import signal_filter\n",
    "from gen_plots import display_interesting_variables, display_all_variables\n",
    "from Battery_Kalman.soc_estimator import SocEstimator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'browser'\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# DANGEROUS DONT DO\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "#px.set_mapbox_access_token(open(\".mapbox_token\").read())\n",
    "\n",
    "BATTERY_ENERGY_CAPACITY = 752.4 # Kilo Joules\n",
    "\n",
    "#raw_data_path = \"D:/OneDrive - Imperial College London/University Storage/Masters project/data_storage/\"\n",
    "raw_data_path = \"/home/medad/Downloads/MastersProject/Bike_logger/Data_analysis/data_storage/data_storage/\"\n",
    "\n",
    "# Number of PAS magnets\n",
    "N_PAS_MAGNETS = 12\n",
    "\n",
    "# pressure at sea level where the readings are being taken.  \n",
    "qnh=1032.57\n",
    "\n",
    "# read raw data\n",
    "def read_file(filepath):\n",
    "    my_cols = range(19)\n",
    "\n",
    "    date_parser=lambda x: pd.to_datetime(x, errors=\"coerce\", format = \"%Y-%m-%dT%H:%M:%S.%fZ\", utc=True)\n",
    "\n",
    "    \n",
    "    df = pd.read_csv(filepath,\n",
    "                names=my_cols,\n",
    "                engine='c',\n",
    "                parse_dates=[0],\n",
    "                date_parser=date_parser)\n",
    "\n",
    "\n",
    "    df.rename(columns={0: 'Datetime',\n",
    "                           1: 'sensor',\n",
    "                          }, inplace=True)    \n",
    "    \n",
    "    df.dropna(inplace=True, subset=['Datetime'])\n",
    "    \n",
    "    df.sort_values(by='Datetime',inplace = True)\n",
    "\n",
    "\n",
    "    df = df[~(df['Datetime'] < '2020-03-12 18:46:00')]\n",
    "    \n",
    "        \n",
    "    return df\n",
    "\n",
    "\n",
    "def filter_df_signal(df, input_name, output_name, highcut_f):\n",
    "    df[output_name] = signal_filter(df[input_name], highcut=highcut_f, method='butterworth_ba', order=5)\n",
    "    return df\n",
    "\n",
    "\n",
    "def energy_from_power_time(datetime_series, power_series):\n",
    "    \"\"\"\n",
    "    Return power in kilo joules\n",
    "    \"\"\"\n",
    "    max_seconds = 1\n",
    "    \n",
    "    time_delta = datetime_series.diff().dt.total_seconds().fillna(0)\n",
    "    energy = power_series*time_delta\n",
    "    \n",
    "    energy = energy[time_delta < max_seconds]\n",
    "    \n",
    "    return energy.sum()/1000000\n",
    "\n",
    "def pulse_width_pas_to_rpm(pulse_width):   \n",
    "    return 1000000/pulse_width/N_PAS_MAGNETS\n",
    "\n",
    "def pulse_width_to_rpm(pulse_width):   \n",
    "    return 1000000/pulse_width\n",
    "\n",
    "def get_altitude(pressure,temperature):\n",
    "    # The temperature should be the outdoor temperature. \n",
    "    # Use the manual_temperature variable if temperature adjustments are required.\n",
    "    altitude = ((pow((qnh / pressure), (1.0 / 5.257)) - 1) * (temperature + 273.15)) / 0.0065\n",
    "    return altitude\n",
    "\n",
    "def insert_time(row):\n",
    "    return row['Datetime'].replace(minute=int(row['minute']),second=int(row['second']),microsecond=int(row['millisecond']*1000))\n",
    "\n",
    "def process_gps(df):\n",
    "    mask = df[\"sensor\"] == 'gps'\n",
    "    df_gps = df[mask]\n",
    "\n",
    "    df_gps.rename(columns={2: 'hour',\n",
    "                           3: 'minute',\n",
    "                           4: 'second',\n",
    "                           5: 'millisecond',\n",
    "                           6: 'latitude',\n",
    "                           7: 'longitude',\n",
    "                           8: 'altitude',\n",
    "                           9: 'GPS Speed',\n",
    "                           10: 'sats',\n",
    "                           11: 'gnssFixOK',\n",
    "                           12: 'fix_type',\n",
    "                           13: 'vehicle_heading',\n",
    "                           14: 'horizontal_accuracy', # Horizontal accuracy estimate: mm\n",
    "                           15: 'vertical_accuracy',   #  Vertical accuracy estimate: mm\n",
    "                           16: 'speed_accuracy',     # Speed accuracy estimate: mm/s\n",
    "                           17: 'heading_accuracy'    # Heading accuracy estimate (both motion and vehicle): deg\n",
    "                          }, inplace=True)\n",
    "\n",
    "    \n",
    "    df_gps['Datetime'] = df_gps.apply(lambda r: insert_time(r), axis=1)\n",
    "    df_gps.sort_values(by='Datetime',inplace = True)\n",
    "    \n",
    "    df_gps = df_gps[df_gps['gnssFixOK'] == 1]\n",
    "\n",
    "    \n",
    "    offset = 9.5 # seconds\n",
    "    df_gps[\"Datetime\"] = df_gps[\"Datetime\"] - pd.Timedelta(offset, unit='s')\n",
    "\n",
    "    \n",
    "\n",
    "    time_delta = df_gps[\"Datetime\"].diff().dt.total_seconds().fillna(0)\n",
    "    df_gps['gps_acceleration'] = df_gps[\"GPS Speed\"].diff()/time_delta\n",
    "    \n",
    "    \n",
    "    x = df_gps[\"longitude\"].diff().fillna(0)\n",
    "    y = df_gps[\"latitude\"].diff().fillna(0)\n",
    "    \n",
    "    x = signal_filter(x, highcut=100, method='butterworth_ba', order=5)\n",
    "    y = signal_filter(y, highcut=100, method='butterworth_ba', order=5)\n",
    "\n",
    "    phi, df_gps['heading'] = cart2pol(x, y)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    df_gps.dropna(axis=1, how='all',inplace=True)\n",
    "    df_gps.head()\n",
    "    \n",
    "    return df_gps\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def process_imu(df):\n",
    "    mask = df[\"sensor\"] == 'imu'\n",
    "    df_imu = df[mask]\n",
    "\n",
    "    df_imu.rename(columns={2: 'acceleration_x',\n",
    "                           3: 'acceleration_y',\n",
    "                           4: 'acceleration_z',\n",
    "                           5: 'gyro_x',\n",
    "                           6: 'gyro_y',\n",
    "                           7: 'gyro_z',\n",
    "                          }, inplace=True)\n",
    "\n",
    "    df_imu.dropna(axis=1, how='all',inplace=True)\n",
    "    \n",
    "    df_imu = filter_df_signal(df_imu, \"gyro_x\", \"gyro_x_filtered\", 10 )\n",
    "    df_imu = filter_df_signal(df_imu, \"acceleration_x\", \"acceleration_x_filtered\", 10 )\n",
    "\n",
    "\n",
    "    return df_imu\n",
    "\n",
    "def process_brake(df):\n",
    "    mask = df[\"sensor\"] == 'brake_state'\n",
    "    df_brake = df[mask]\n",
    "\n",
    "    df_brake.rename(columns={2: 'brake_state',\n",
    "                          }, inplace=True)\n",
    "\n",
    "    df_brake.dropna(axis=1, how='all',inplace=True)\n",
    "    return df_brake\n",
    "\n",
    "\n",
    "def process_pas(df):\n",
    "    mask = df[\"sensor\"] == 'pas'\n",
    "    df_pas = df[mask]\n",
    "\n",
    "\n",
    "    df_pas.rename(columns={2: 'pulse_delay_us',\n",
    "                          }, inplace=True)\n",
    "    df_pas.dropna(axis=1, how='all',inplace=True)\n",
    "    df_pas = df_pas[df_pas['pulse_delay_us'] > 4000]\n",
    "\n",
    "    df_pas['pas_rpm'] = df_pas.apply(lambda x: pulse_width_pas_to_rpm(x['pulse_delay_us']), axis=1)\n",
    "\n",
    "    df_pas.head()\n",
    "    \n",
    "    return df_pas\n",
    "    \n",
    "def process_motor_speed(df, df_gps):\n",
    "    mask = df[\"sensor\"] == 'motor_speed'\n",
    "    df_ms = df[mask]\n",
    "\n",
    "    df_ms.rename(columns={2: 'pulse_delay_us',\n",
    "                          }, inplace=True)\n",
    "    \n",
    "    df_ms.dropna(axis=1, how='all',inplace=True)\n",
    "    \n",
    "    df_ms = df_ms[df_ms['pulse_delay_us'] > 15000]\n",
    "\n",
    "\n",
    "    df_ms['motor_rpm'] = df_ms.apply(lambda x: pulse_width_to_rpm(x['pulse_delay_us']), axis=1)\n",
    "    \n",
    "    df_ms_merged = pd.merge_asof(df_ms, df_gps, on = 'Datetime', direction = 'nearest')\n",
    "    \n",
    "    multiplier = df_ms_merged['GPS Speed'].div(df_ms_merged['motor_rpm'], axis = 0).mean()\n",
    "\n",
    "    \n",
    "    \n",
    "    df_ms['motor_rpm'] = df_ms['motor_rpm'] * multiplier\n",
    "    \n",
    "    \n",
    "    time_delta = df_ms[\"Datetime\"].diff().dt.total_seconds().fillna(0)\n",
    "    df_ms['filtered_motor_rpm'] = signal_filter(df_ms['motor_rpm'], highcut=100, method='butterworth_ba', order=5)\n",
    "    df_ms['motor_acceleration'] = df_ms[\"filtered_motor_rpm\"].diff()/time_delta\n",
    "\n",
    "\n",
    "    \n",
    "    return df_ms\n",
    "\n",
    "def process_ina(df):    \n",
    "    mask = df[\"sensor\"] == 'ina226'\n",
    "    df_ina = df[mask]\n",
    "    \n",
    "    SHUNT_RESISTANCE = 0.00215 # ohms\n",
    "\n",
    "    df_ina.rename(columns={2: 'INA226 ID',\n",
    "                           3: 'Voltage_V',\n",
    "                           4: 'V_shunt',\n",
    "                           5: 'Current_uncalibrated',\n",
    "                           6: 'Power_uncalibrated',\n",
    "                          }, inplace=True)\n",
    "    df_ina.dropna(axis=1, how='all',inplace=True)\n",
    "    df_ina.reset_index()\n",
    "\n",
    "\n",
    "    df_ina = df_ina[df_ina[\"Voltage_V\"] != 0]\n",
    "    \n",
    "    df_ina[\"Current\"] = df_ina[\"V_shunt\"] / SHUNT_RESISTANCE\n",
    "    df_ina[\"Power\"] = df_ina[\"Current\"] * df_ina[\"Voltage_V\"]\n",
    "\n",
    "    df_ina[\"Power_averaged\"] = signal_filter(df_ina['Power'], highcut=30, method='butterworth_ba', order=2)\n",
    "#     df_ina[\"Current_averaged\"] = signal_filter(df_ina['Current'], highcut=6, method='butterworth_ba', order=2)\n",
    "#     df_ina[\"Voltage_V_averaged\"] = signal_filter(df_ina['Voltage_V'], highcut=6, method='butterworth_ba', order=2)\n",
    "\n",
    "\n",
    "    print(\"Total Energy Consumption[KiloJoules]\",energy_from_power_time(df_ina[\"Datetime\"],df_ina[\"Power\"]))\n",
    "    df_ina.head()\n",
    "    \n",
    "    return df_ina\n",
    "\n",
    "def process_baro(df,df_ms, df_gps):\n",
    "    mask = df[\"sensor\"] == 'baro'\n",
    "    df_baro = df[mask]\n",
    "\n",
    "    df_baro.rename(columns={2: 'temperature',\n",
    "                           3: 'Pressure',\n",
    "                           4: 'humidity',\n",
    "                          }, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    df_baro['Baro_Altitude'] = df_baro.apply(lambda x: get_altitude(x['Pressure'], x['temperature']), axis=1)\n",
    "    df_baro['filtered_Baro_Altitude'] = signal_filter(df_baro['Baro_Altitude'], highcut=10, method='butterworth_ba', order=2)\n",
    "\n",
    "    df_baro_ms = pd.merge_asof(df_baro, df_ms, on = 'Datetime', direction = 'forward')\n",
    "    df_baro_merged = pd.merge_asof(df_baro, df_gps, on = 'Datetime', direction = 'forward')\n",
    "    \n",
    "    \n",
    "    \n",
    "    offset = df_baro_merged['Baro_Altitude'].sub(df_baro_merged['altitude'], axis = 0).mean()\n",
    "    \n",
    "\n",
    "    time_delta = df_baro[\"Datetime\"].diff().dt.total_seconds().fillna(0)\n",
    "    df_baro['vertical_distance'] = df_baro[\"filtered_Baro_Altitude\"].diff()\n",
    "    df_baro['vertical_velocity'] = df_baro['vertical_distance']/time_delta\n",
    "    df_baro['slope'] = df_baro[\"filtered_Baro_Altitude\"].diff()/(time_delta * df_baro_ms[\"filtered_motor_rpm\"])\n",
    "    \n",
    "    df_baro['Barometric_Altitude_Uncalibrated'] = df_baro['Baro_Altitude']\n",
    "    df_baro['Baro_Altitude'] = df_baro['Baro_Altitude'] - offset\n",
    "    df_baro['filtered_Baro_Altitude'] = df_baro['filtered_Baro_Altitude'] - offset\n",
    "\n",
    "\n",
    "\n",
    "    df_baro.dropna(axis=1, how='all',inplace=True)\n",
    "\n",
    "    df_baro.head()\n",
    "    \n",
    "    return df_baro\n",
    "\n",
    "def process(df):\n",
    "    print(\"Start GPS process\")\n",
    "    df_gps = process_gps(df)\n",
    "    print(\"GPS process DONE....\")\n",
    "    \n",
    "    df_pas = process_pas(df)\n",
    "    print(\"PAS process DONE....\")\n",
    "    \n",
    "    df_ms = process_motor_speed(df, df_gps)\n",
    "    print(\"Motor Speed process DONE....\")\n",
    "\n",
    "    df_ina = process_ina(df)\n",
    "    print(\"INA226 process DONE....\")\n",
    "\n",
    "    df_baro = process_baro(df,df_ms,df_gps)\n",
    "    print(\"Barometer process DONE....\")\n",
    "\n",
    "    df_imu = process_imu(df)\n",
    "    print(\"IMU process DONE....\")\n",
    "\n",
    "    df_brake = process_brake(df)\n",
    "    print(\"Brake process DONE....\")\n",
    "\n",
    "\n",
    "    return df_ina, df_gps, df_baro, df_pas, df_ms, df_imu, df_brake\n",
    "\n",
    "def display_gps_positions(df_gps):\n",
    "    \"\"\"\n",
    "    Display GPS positions\n",
    "    \"\"\"\n",
    "    # Display GPS positions\n",
    "    fig = px.line_mapbox(df_gps,\n",
    "                            lat=\"latitude\",\n",
    "                            lon=\"longitude\",\n",
    "                            color=\"trip\",#\"slope\",#\"LOCATION Altitude ( m)\",,#\"Speed(km/h)\", # \"abs_acceleration\" or \"gps_acceleration\" or \"power\"\n",
    "                            zoom=14,\n",
    "                            hover_data=[\"Datetime\", \"altitude\",\"sats\", \"heading\"],\n",
    "                            #size=\"LOCATION Accuracy ( m)\"\n",
    "                           )\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(mapbox_style=\"carto-positron\")\n",
    "    fig.update_layout(margin={\"r\": 0, \"t\": 0, \"l\": 0, \"b\": 0})\n",
    "    fig.write_html(\"output/GPS_track.html\")\n",
    "    fig.show()\n",
    "\n",
    "def process_charge_data(fps):\n",
    "    dfs  = [read_file(fp) for fp in fps]\n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    df_ina = process_ina(df)\n",
    "    return df_ina\n",
    "\n",
    "def display_charge_data(df_ina):\n",
    "    \n",
    "    \n",
    "    FEATURES = [\"Voltage_V_averaged\",\"Current_averaged\",\"Power_averaged\"]\n",
    "    TITLES = [\"Battery Voltage[V]\",\"Current[mA]\",\"Power[mW]\"]\n",
    "\n",
    "    N_FEATURES = len(FEATURES)\n",
    "    fig = make_subplots(rows=N_FEATURES, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01)\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "    for i, feature in enumerate(FEATURES):\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_ina.index,\n",
    "            y=df_ina[feature],\n",
    "            name=feature,\n",
    "            hoverinfo='y'),\n",
    "            row=i+1, col=1)\n",
    "        \n",
    "#         non_averaged_feature = feature.replace(\"_averaged\",\"\")\n",
    "#         fig.add_trace(go.Scatter(\n",
    "#             x=df_ina.index,\n",
    "#             y=df_ina[non_averaged_feature],\n",
    "#             name=non_averaged_feature,\n",
    "#             hoverinfo='y'),\n",
    "#             row=i+1, col=1)\n",
    "\n",
    "        fig.update_yaxes(title_text=TITLES[i], row=i+1, col=1)\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"Power Parameters\")\n",
    "\n",
    "    fig.write_html(\"output/Charging_Power_variables.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "# params_x_for_ml = ['Voltage_V', 'V_shunt', 'Current', 'temperature', 'Pressure', 'humidity',\n",
    "#                   'Baro_Altitude', 'filtered_Baro_Altitude', 'motor_rpm_x', 'motor_acceleration_x', 'filtered_motor_rpm_x', 'slope',\n",
    "#                   'latitude', 'longitude', 'altitude', 'GPS Speed', 'sats', 'gnssFixOK', 'fix_type', 'gps_acceleration',\n",
    "#                   'pas_rpm', 'motor_rpm_y', 'motor_acceleration_y', 'filtered_motor_rpm_y','acceleration_x','acceleration_y','acceleration_z',\n",
    "#                    'gyro_x','gyro_y','gyro_z', 'brake_state']\n",
    "\n",
    "\n",
    "# params_x_for_ml = ['temperature', 'Pressure', 'humidity','filtered_Baro_Altitude', 'filtered_motor_rpm_x', 'slope',\n",
    "#                   'latitude', 'longitude', 'altitude', 'GPS Speed','acceleration_x','acceleration_y',\n",
    "#                     'acceleration_z','gyro_x','gyro_y','gyro_z'\n",
    "#                  ]\n",
    "\n",
    "\n",
    "params_x_for_ml = ['temperature', \n",
    "                   'Pressure', \n",
    "                   'humidity',\n",
    "                   'filtered_Baro_Altitude',\n",
    "                   'slope',\n",
    "                   'latitude',\n",
    "                   'longitude',\n",
    "                   'altitude',\n",
    "                   \"heading\",\n",
    "                   \"SOC\",\n",
    "                   #\"vertical_distance\",\n",
    "                   \"vertical_velocity\",\n",
    "                   \"GPS Speed\",\n",
    "                   'acceleration_x','acceleration_y', 'acceleration_z',\n",
    "                   'gyro_x','gyro_y','gyro_z',\n",
    "                   'filtered_motor_rpm',\n",
    "                   'pas_rpm'\n",
    "                   \n",
    "                   \n",
    "                 ]\n",
    "\n",
    "\n",
    "# params_x_for_ml = ['temperature', \n",
    "#                    'Pressure', \n",
    "#                    'humidity',\n",
    "#                    'filtered_Baro_Altitude',\n",
    "#                    'slope',\n",
    "#                    'latitude',\n",
    "#                    'longitude',\n",
    "#                    'altitude',\n",
    "#                    \"heading\",\n",
    "#                    \"SOC\",\n",
    "#                    \"vertical_distance\",\n",
    "# #                    \"vertical_velocity\",\n",
    "# #                    \"GPS Speed\"\n",
    "#                  ]\n",
    "\n",
    "params_y_for_ml = \"Power\"\n",
    "\n",
    "params_x_for_ml_soc = ['temperature', \"Voltage_V\", \"Current\", \"Power\"]\n",
    "params_y_for_ml_soc = \"SOC\"\n",
    "\n",
    "\n",
    "\n",
    "def drop_sensor_column(df, column_name):\n",
    "    return df[df.columns.difference([column_name])]\n",
    "\n",
    "    \n",
    "    \n",
    "def gen_ml_data(dataframes):\n",
    "    \"\"\"\n",
    "    The first data frame in dataframes should have the highest datarate\n",
    "    \"\"\"\n",
    "    \n",
    "    column_name = \"sensor\"\n",
    "    \n",
    "    \n",
    "    print(\"Dropping Sensor column....\")\n",
    "    for i in dataframes:\n",
    "        i.drop(column_name, axis=1, inplace=True)\n",
    "\n",
    "    \n",
    "        \n",
    "    print(\"Merging Dataframes....\")\n",
    "\n",
    "    df_ml = dataframes[0]\n",
    "\n",
    "    for df in dataframes[1:]:\n",
    "        df_ml = pd.merge_asof(df_ml, df, on = 'Datetime', direction = 'forward')\n",
    "    print(\"Done merging Dataframes....\")\n",
    "\n",
    "\n",
    "    return df_ml\n",
    "\n",
    "def split_x_y(df_ml, params_x_for_ml, params_y_for_ml):\n",
    "    x, y = df_ml[params_x_for_ml], df_ml[params_y_for_ml]\n",
    "    return x, y\n",
    "\n",
    "def concat_dfs(fps):\n",
    "    dfs = []\n",
    "    trip_counter = 0\n",
    "    \n",
    "    for fp in fps:\n",
    "        df = read_file(fp)\n",
    "        print(\"Trip Count: \", trip_counter)\n",
    "\n",
    "        df[\"trip\"] = trip_counter\n",
    "        \n",
    "        dfs.append(df)\n",
    "        trip_counter+=1\n",
    "    \n",
    "    df = pd.concat(dfs, ignore_index=True)\n",
    "    return df\n",
    "\n",
    "def get_raw_dfs(fps):\n",
    "    df = concat_dfs(fps)\n",
    "    raw_dfs = process(df)\n",
    "    \n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "    return raw_dfs\n",
    "    \n",
    "\n",
    "def remove_rows_with_na_in_column(df, column):\n",
    "    return df[df[column].notna()]\n",
    "\n",
    "def process_for_ml(fps):\n",
    "    \"\"\"\n",
    "    Takes in list of file paths, concats and processes them\n",
    "    Set display_variables = True to visualise the variables.\n",
    "    \"\"\"\n",
    "    raw_dfs = get_raw_dfs(fps)\n",
    "    \n",
    "    # Highest datarate must be in the start of the list\n",
    "    df_ml = gen_ml_data(raw_dfs)\n",
    "    #df_ml = remove_rows_with_na_in_column(df_ml, \"trip\")\n",
    "    \n",
    "    \n",
    "    return df_ml, raw_dfs\n",
    "\n",
    "def get_energy_error(predicted_energy, actual_energy):\n",
    "    Error = 100 * (predicted_energy - actual_energy)/actual_energy\n",
    "    print(\"Actual energy:\",actual_energy, \"Predicted Energy:\", predicted_energy, \"Error[%](ideal should be 0%):\", Error, \"%\")\n",
    "    return Error\n",
    "    \n",
    "\n",
    "def print_power_consumption_score(timestamps, ytest, ypred):\n",
    "    actual_energy = energy_from_power_time(timestamps, ytest)\n",
    "    predicted_energy = energy_from_power_time(timestamps, ypred)\n",
    "    error = get_energy_error(predicted_energy, actual_energy)\n",
    "    return error\n",
    "\n",
    "\n",
    "def print_test_results(xgbr, df_ml):\n",
    "    x, y = split_x_y(df_ml, params_x_for_ml, params_y_for_ml)\n",
    "    ypred = xgbr.predict(x)\n",
    "    \n",
    "    timestamps = df_ml[\"Datetime\"]\n",
    "    print(\"Test Results :: \")\n",
    "    error = print_power_consumption_score(timestamps, y, ypred)\n",
    "    return error\n",
    "\n",
    "def do_ml(x,y):\n",
    "\n",
    "    xgbr = xgb.XGBRegressor(verbosity=1,tree_method='gpu_hist', gpu_id=0)\n",
    "    print(xgbr)\n",
    "\n",
    "    xgbr.fit(x, y)\n",
    "\n",
    "    print(\"Training score: \", xgbr.score(x, y))\n",
    "\n",
    "    _ = plot_importance(xgbr, height=0.9)\n",
    "    \n",
    "    return xgbr\n",
    "\n",
    "\n",
    "## SOC Calculations\n",
    "\n",
    "def coulomb_counting(df):\n",
    "    \"\"\"\n",
    "    Return SOC series, determined using coulomb counting\n",
    "    \"\"\"\n",
    "    total_capacity_As = 8.708 * 3600 # in As\n",
    "    time_interval =  df[\"Datetime\"].diff().dt.total_seconds().fillna(0)\n",
    "    energy  = (df[\"Current\"]/1000) * time_interval # Convert power from mA to A\n",
    "    remaining_energy = total_capacity_As - energy.cumsum()\n",
    "    soc = remaining_energy / total_capacity_As\n",
    "    return soc\n",
    "\n",
    "def thevenin_model(df):\n",
    "    \"\"\"\n",
    "    Return SOC series, determined from Current and Voltage only.\n",
    "    \"\"\"\n",
    "    total_capacity_As = 8.708 * 3600 # in As\n",
    "    time_interval = df[\"Datetime\"].diff().dt.total_seconds().fillna(0)\n",
    "    energy  = (df[\"Current\"]/1000) * time_interval # Convert power from mA to A\n",
    "    remaining_energy = total_capacity_As - energy.cumsum()\n",
    "    soc = remaining_energy / total_capacity_As\n",
    "    return soc\n",
    "\n",
    "def ML_trained_by_coulomb_counting(df):\n",
    "    \"\"\"\n",
    "    Return SOC series, determined from ML model, trained on Coulomb counting. \n",
    "    Uses Voltage, Current, Power and Temperature to determine SOC\n",
    "    \"\"\"\n",
    "    x = df[params_x_for_ml_soc] # WARNING: df_ml_test must be a full discharge of battery from full to empty\n",
    "    soc = xgbr_SOC.predict(x)\n",
    "    return soc\n",
    "\n",
    "def add_soc_feature(df, method):\n",
    "    soc = method(df)\n",
    "    df.loc[:,\"SOC\"] = soc\n",
    "\n",
    "def plot_predicted_data(timestamps, ytest, ypred):\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_traces(go.Scatter(x=timestamps, y=ytest, name='Actual data'))\n",
    "    fig.add_traces(go.Scatter(x=timestamps, y=ypred, name='Regression Fit'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"Power consumption, predicted\",\n",
    "        xaxis_title=\"Time(UTC)\",\n",
    "        yaxis_title=\"Power[mW]\",\n",
    "    )\n",
    "    fig.write_html(\"output/Predicted_plot.html\")\n",
    "\n",
    "    fig.show()\n",
    "    \n",
    "def score_predicted_data_xgboost(model, df_ml_test):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    ypred = model.predict(x)\n",
    "    error = print_power_consumption_score(df_ml_test[\"Datetime\"], y, ypred)\n",
    "    return y, ypred, error\n",
    "\n",
    "def make_predictions_xgboost(model, df_ml_test, plot=True):\n",
    "    y, ypred, error = score_predicted_data_xgboost(model, df_ml_test)\n",
    "    if plot == True:\n",
    "        plot_predicted_data(df_ml_test[\"Datetime\"], y, ypred)\n",
    "    return error\n",
    "\n",
    "def plot_3d_plot(df_gps, df_baro, df_ina):\n",
    "    \n",
    "    df = pd.merge_asof(df_gps,df_baro , on = 'Datetime', direction = 'nearest')\n",
    "    df = pd.merge_asof(df,df_ina , on = 'Datetime', direction = 'nearest')\n",
    "\n",
    "    fig = go.Figure(data=go.Scatter3d(\n",
    "        x=df[\"longitude\"],\n",
    "        y=df[\"latitude\"],\n",
    "        z=df[\"Baro_Altitude\"],\n",
    "        marker=dict(\n",
    "            size=4,\n",
    "            color=df[\"Power\"],\n",
    "            colorscale='Viridis',\n",
    "            showscale=True,\n",
    "            colorbar=dict(\n",
    "                title=\"Power[mW]\"\n",
    "            )\n",
    "\n",
    "        ),\n",
    "        text = 'Power:' +df[\"Power\"].astype(str),\n",
    "        line=dict(\n",
    "            color='darkblue',\n",
    "            width=2\n",
    "        ),\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        #height=700,\n",
    "        #autosize=False,\n",
    "        scene=dict(\n",
    "            xaxis = dict(title='Longitude'),\n",
    "            yaxis = dict(title='Latitude'),\n",
    "            zaxis = dict(title='Barometric Altitude'),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.write_html(\"output/gps_speed_3d.html\")\n",
    "    fig.show()\n",
    "\n",
    "def show_correlations_in_df(df):\n",
    "    \"\"\"\n",
    "    Show correlations between all the columns in df\n",
    "    \"\"\"\n",
    "    fig = px.imshow(df.corr(), title='Heatmap of co-relation between variables')\n",
    "    fig.write_html(\"output/Correlation_heatmap.html\")\n",
    "    fig.show()\n",
    "\n",
    "def remove_values_from_list(lst, value):\n",
    "    \"\"\"\n",
    "    Remove all occurances of value from lst, and return the list minus those values\n",
    "    \"\"\"\n",
    "    return list(filter((value).__ne__, lst))\n",
    "\n",
    "def plot_linear_correlations(df):\n",
    "    \"\"\"\n",
    "    plot all X-features against output variable Power\n",
    "    \"\"\"\n",
    "    col_= df.columns.tolist()\n",
    "    col_ = remove_values_from_list(col_, \"sensor_y\")\n",
    "    col_ = remove_values_from_list(col_, \"sensor_x\")\n",
    "\n",
    "    for i in col_[10:]:\n",
    "        fig = px.scatter(df, x=i, y=\"Power\", title='{0} vs Power'.format(i))\n",
    "        fig.write_html(\"output/Correlation_display_{}_vs_Power.html\".format(i))\n",
    "\n",
    "        fig.show()\n",
    "\n",
    "def get_masked_items(df, column, items):\n",
    "    return df[df[column].isin(items)]\n",
    "\n",
    "\n",
    "\n",
    "def special_test_train_split(df_ml, test_size=0.15, random_state=42):\n",
    "    \"\"\"\n",
    "    return test, train dataframes\n",
    "    \"\"\"\n",
    "\n",
    "    train_frac = 1 - test_size\n",
    "    l = df_ml[\"trip\"].unique()\n",
    "    \n",
    "    print(l)\n",
    "    \n",
    "    sz = len(l)\n",
    "    cut = int(train_frac * sz) #80% of the list\n",
    "    print(cut)\n",
    "    random.seed(random_state)\n",
    "    random.shuffle(l) # inplace shuffle\n",
    "    train_trips = l[:cut] # first 80% of shuffled list\n",
    "    test_trips = l[cut:] # last 20% of shuffled list\n",
    "    \n",
    "    \n",
    "    print(l, train_trips, test_trips)\n",
    "    \n",
    "    return get_masked_items(df_ml, \"trip\", test_trips), get_masked_items(df_ml, \"trip\", train_trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run if df_ml has been saved\n",
    "\n",
    "df_ml, raw_dfs = process_for_ml([\n",
    "# raw_data_path+\"hampsted_trip_1-4-2021.csv\",\n",
    "# raw_data_path+\"data_19-4-21.csv\",\n",
    "# raw_data_path+\"data_icah_20-4-21.csv\",\n",
    "# raw_data_path+\"data_27-4-21.csv\",\n",
    "# raw_data_path+\"data_28-4-21.csv\",                                          \n",
    "# raw_data_path+\"data_6-5-21.csv\",\n",
    "raw_data_path+\"data_8-5-2021.csv\",\n",
    "raw_data_path+\"data_10-5-21.csv\",\n",
    "raw_data_path+\"data_10-5-21-v2.csv\",\n",
    "raw_data_path+\"data_11-5-21.csv\",\n",
    "raw_data_path+\"data_12-5-21-v1.csv\",\n",
    "raw_data_path+\"data_12-5-21-v2.csv\",\n",
    "raw_data_path+\"data_13-5-21-clean.csv\",\n",
    "raw_data_path+\"data_14-5-21-putney-heath-circuit.csv\",\n",
    "raw_data_path+\"data_15-5-21.csv\",\n",
    "raw_data_path+\"data_18-5-21_enoch.csv\",\n",
    "raw_data_path+\"data_20-5-21_v1.csv\",\n",
    "raw_data_path+\"data_20-5-21_v2.csv\",\n",
    "raw_data_path+\"data_20-5-21_v3.csv\",\n",
    "raw_data_path+\"data_21-5-21_v1.csv\",\n",
    "raw_data_path+\"data_21-5-21_v2.csv\",\n",
    "])\n",
    "\n",
    "df_ml.to_pickle(\"df_ml.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ml = pd.read_pickle(\"df_ml.pkl\")\n",
    "df_ml_test, df_ml_train = special_test_train_split(df_ml, test_size=0.1, random_state=58)\n",
    "del df_ml\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run if df_ml_soc_trainer has been saved\n",
    "df_ml_soc_trainer, _ = process_for_ml([raw_data_path+\"data_17-5-21.csv\"])\n",
    "df_ml_soc_trainer.to_pickle(\"df_ml_soc_trainer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train ML model to predict SOC from voltage and Current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No need to run if model has been saved.\n",
    "df_ml_soc_trainer = pd.read_pickle(\"df_ml_soc_trainer.pkl\")\n",
    "add_soc_feature(df_ml_soc_trainer, coulomb_counting)\n",
    "x, y = split_x_y(df_ml_soc_trainer, params_x_for_ml_soc, params_y_for_ml_soc) # WARNING: df_ml_test must be a full discharge of battery from full to empty\n",
    "xgbr_SOC = do_ml(x, y)\n",
    "xgbr_SOC.save_model('xgbr_SOC_model.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add SOC as a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbr_SOC = xgb.XGBRegressor()\n",
    "xgbr_SOC.load_model('xgbr_SOC_model.json')\n",
    "add_soc_feature(df_ml_train, ML_trained_by_coulomb_counting)\n",
    "add_soc_feature(df_ml_test, ML_trained_by_coulomb_counting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display variables for initial viewing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_all_variables(*raw_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_gps_positions(raw_dfs[1]) # df_gps is index 1 TODO: don't use indexes. use labels for readiblity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process and Display Charging data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: Ensure 1970 filter is removed, because the data is not timestamped\n",
    "df_ina = process_charge_data([raw_data_path+\"data_charge_14-5-21.csv\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_ina_df(df_ina):\n",
    "    df_ina = df_ina.set_index(\"Datetime\")\n",
    "    df_ina = df_ina.resample('1S').mean()\n",
    "\n",
    "    display_charge_data(df_ina)\n",
    "\n",
    "df_ina_subset = df_ina.head(2500000)\n",
    "# Display charging profile\n",
    "resample_ina_df(df_ina_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_correlations_in_df(df_ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import ascii_letters\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\")\n",
    "\n",
    "# Generate a large random dataset\n",
    "rs = np.random.RandomState(33)\n",
    "d = df_ml_train\n",
    "\n",
    "# Compute the correlation matrix\n",
    "corr = d.corr()\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## WARNING: It will open a lot of tabs!!\n",
    "plot_linear_correlations(df_ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more data exploration through visualizing\n",
    "\n",
    "def showDistributions(df2, category1, category2, category3):\n",
    "    fig, axes = plt.subplots(1,3, figsize=(25, 5))\n",
    "    sns.histplot(data=df2, x=category1, kde=True, color=\"darkseagreen\", ax=axes[0])\n",
    "    axes[0].set_title(\"Distribution of {}\".format(category1))\n",
    "    sns.histplot(data=df2, x=category2, kde=True, color=\"darkseagreen\", ax=axes[1])\n",
    "    axes[1].set_title(\"Distribution of {}\".format(category2))\n",
    "    sns.histplot(data=df2, x=category3, kde=True, color=\"darkseagreen\", ax=axes[2])\n",
    "    axes[2].set_title(\"Distribution of {}\".format(category3))\n",
    "\n",
    "showDistributions(df_ml_train, \"Voltage_V\", \"Current\", \"Power\")\n",
    "showDistributions(df_ml_train, \"GPS Speed\", \"altitude\", \"gps_acceleration\")\n",
    "showDistributions(df_ml_train, \"heading\", \"Baro_Altitude\", \"Pressure\")\n",
    "showDistributions(df_ml_train, \"humidity\", \"slope\", \"temperature\")\n",
    "showDistributions(df_ml_train, \"pas_rpm\", \"motor_rpm\", \"brake_state\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show pairplots of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "sns.set_theme()\n",
    "\n",
    "features_to_pair_plot = [\n",
    "    \"Voltage_V\",\n",
    "    \"Current\",\n",
    "    \"Power\",\n",
    "    \"SOC\",\n",
    "    #\"heading\",\n",
    "    \"Baro_Altitude\",\n",
    "    #\"filtered_Baro_Altitude\"\n",
    "    #\"Pressure\",\n",
    "    \"slope\",\n",
    "    \"temperature\",\n",
    "    \"pas_rpm\",\n",
    "    \"motor_rpm\",\n",
    "#     \"brake_state\",\n",
    "#     \"GPS Speed\",\n",
    "#     \"altitude\",\n",
    "#     \"gps_acceleration\"\n",
    "#     \"humidity\"\n",
    "]\n",
    "\n",
    "battery_params = [\n",
    "    \"Voltage_V\",\n",
    "    \"Current\",\n",
    "    \"Power\",\n",
    "    \"SOC\",\n",
    "    \"Baro_Altitude\",\n",
    "]\n",
    "\n",
    "def do_pair_plot(df, features, title):\n",
    "    g = sns.pairplot(\n",
    "        df[features].sample(n=10000, random_state=1),\n",
    "        plot_kws={\"s\": 1}\n",
    "    )\n",
    "    \n",
    "    g.fig.suptitle(\n",
    "        title,\n",
    "        y=1.001 # y= some height>1\n",
    "    ) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_pair_plot(df_ml_train, features_to_pair_plot, \"Pair Plot of E-bike parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_pair_plot(df_ml_train, battery_params, \"Pair Plot of E-bike Battery parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime',\n",
    "#  'INA226 ID',\n",
    "#  'Power',\n",
    "#  'Power_averaged',\n",
    "#  'Power_uncalibrated',\n",
    "#  'V_shunt',\n",
    "#  'Voltage_V',\n",
    " 'GPS Speed',\n",
    "#  'altitude',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'gps_acceleration',\n",
    "#  'heading',\n",
    "#  'hour',\n",
    "#  'latitude',\n",
    "#  'longitude',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "#  'sats',\n",
    "#  'second',\n",
    "#  'Baro_Altitude',\n",
    "#  'Pressure',\n",
    "#  'filtered_Baro_Altitude',\n",
    "#  'humidity',\n",
    "#  'slope',\n",
    "#  'temperature',\n",
    "#  'pas_rpm',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "#  'motor_rpm',\n",
    "#  'pulse_delay_us_y',\n",
    "  'acceleration_x',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration_y',\n",
    "#  'acceleration_z',\n",
    "#  'gyro_x',\n",
    "#   'gyro_x_filtered',\n",
    "  'gyro_y',\n",
    "#  'gyro_z',\n",
    "#  'brake_state',\n",
    "  'SOC'\n",
    "]\n",
    "do_pair_plot(df_ml_train, params_of_interest, \"Pair Plot of E-bike parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime',\n",
    "#  'INA226 ID',\n",
    "#  'Power',\n",
    "#  'Power_averaged',\n",
    "#  'Power_uncalibrated',\n",
    "#  'V_shunt',\n",
    "#  'Voltage_V',\n",
    " 'GPS Speed',\n",
    "#  'altitude',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'gps_acceleration',\n",
    "#  'heading',\n",
    "#  'hour',\n",
    "#  'latitude',\n",
    "#  'longitude',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "  'sats',\n",
    "#  'second',\n",
    "#  'Baro_Altitude',\n",
    "#  'Pressure',\n",
    "#  'filtered_Baro_Altitude',\n",
    "#  'humidity',\n",
    "#  'slope',\n",
    "#  'temperature',\n",
    "#  'pas_rpm',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "  'motor_rpm',\n",
    "#  'pulse_delay_us_y',\n",
    "#   'acceleration_x',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration_y',\n",
    "#  'acceleration_z',\n",
    "#  'gyro_x',\n",
    "#   'gyro_x_filtered',\n",
    "#   'gyro_y',\n",
    "#  'gyro_z',\n",
    "#  'brake_state',\n",
    "#   'SOC'\n",
    "]\n",
    "do_pair_plot(df_ml_train, params_of_interest, \"Comparison of GPS Speed, Motor Internal Speed and GPS Sats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_of_interest = [\n",
    "#     'Current',\n",
    "#  'Current_uncalibrated',\n",
    "#  'Datetime',\n",
    "#  'INA226 ID',\n",
    "    'Power',\n",
    "#  'Power_averaged',\n",
    "#  'Power_uncalibrated',\n",
    "#  'V_shunt',\n",
    "#  'Voltage_V',\n",
    "  'GPS Speed',\n",
    "#  'altitude',\n",
    "#  'fix_type',\n",
    "#  'gnssFixOK',\n",
    "#  'gps_acceleration',\n",
    "#  'heading',\n",
    "#  'hour',\n",
    "#  'latitude',\n",
    "#  'longitude',\n",
    "#  'millisecond',\n",
    "#  'minute',\n",
    "#   'sats',\n",
    "#  'second',\n",
    "#  'Baro_Altitude',\n",
    "#  'Pressure',\n",
    "#  'filtered_Baro_Altitude',\n",
    "#  'humidity',\n",
    "#  'slope',\n",
    "#  'temperature',\n",
    "#  'pas_rpm',\n",
    "#  'pulse_delay_us_x',\n",
    "#  'filtered_motor_rpm',\n",
    "#  'motor_acceleration',\n",
    "#   'motor_rpm',\n",
    "#  'pulse_delay_us_y',\n",
    "#   'acceleration_x',\n",
    "#   'acceleration_x_filtered',\n",
    "#  'acceleration_y',\n",
    "#  'acceleration_z',\n",
    "#  'gyro_x',\n",
    "#   'gyro_x_filtered',\n",
    "#   'gyro_y',\n",
    "#  'gyro_z',\n",
    "#  'brake_state',\n",
    "#   'SOC'\n",
    "    \"vertical_velocity\",\n",
    "    \"vertical_distance\"\n",
    "    \n",
    "]\n",
    "do_pair_plot(df_ml_train, params_of_interest, \"Comparison of GPS Speed[km/h], Power[mW], Vertical Distance[m], Vertical Speed[m/s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_join_plot(df_ml_train, \"vertical_velocity\", \"Power\", \"vertical_velocity[m/s] vs Power output[mW] from Battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_join_plot(df_ml_train, \"vertical_distance\", \"Power\", \"vertical_velocity[m/s] vs Power output[mW] from Battery\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_join_plot(df, x_param, y_param, title):\n",
    "    p = sns.jointplot(x=x_param,\n",
    "                  y=y_param,\n",
    "                  data=df.sample(n=10000, random_state=1),\n",
    "                  kind=\"reg\",\n",
    "                  scatter_kws={\"s\": 1})\n",
    "    p.fig.suptitle(title)\n",
    "    #p.ax_joint.collections[0].set_alpha(0)\n",
    "    p.fig.tight_layout()\n",
    "    p.fig.subplots_adjust(top=0.95) # Reduce plot to make room \n",
    "    \n",
    "do_join_plot(df_ml_train, \"SOC\", \"Power\", \"State-of-Charge(SOC) vs Power output[mW] from Battery\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export dataframe to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_pickle(df):\n",
    "    print(df.head())\n",
    "    df.to_pickle(\"df_ml_train.pkl\")\n",
    "\n",
    "export_to_pickle(df_ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display SOC vs power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.line(df_ml_train, x=\"SOC\", y=\"Power\", title='SOC vs Power')\n",
    "fig.update_xaxes(autorange=\"reversed\")\n",
    "fig.update_yaxes(title = \"Power[mW]\")\n",
    "fig.write_html(\"output/soc_vs_power.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display SOC vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.line(df_ml_test, x=df_ml_test[\"Datetime\"], y=\"SOC\", title='SOC over Time')\n",
    "fig.update_yaxes(title = \"Power[mW]\")\n",
    "fig.write_html(\"output/soc_vs_power.html\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display barometric altitude vs GPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_barom_vs_gps(raw_dfs):\n",
    "\n",
    "    df_ina, df_gps, df_baro, df_pas, df_ms, df_imu, df_brake = raw_dfs\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                       )\n",
    "\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_baro[\"Datetime\"],\n",
    "        y=df_baro[\"Barometric_Altitude_Uncalibrated\"],\n",
    "        name=\"Barometric Altitude Uncalibrated\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_baro[\"Datetime\"],\n",
    "        y=df_baro[\"Baro_Altitude\"],\n",
    "        name=\"Barometric Altitude Calibrated\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_baro[\"Datetime\"],\n",
    "        y=df_gps[\"altitude\"],\n",
    "        name=\"GPS Altitude\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.update_yaxes(title_text=\"Altitude[m]\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Time\", row=1, col=1)\n",
    "\n",
    "\n",
    "    fig.update_layout(title_text=\"GPS Altitude vs Barometric Altitude\")\n",
    "\n",
    "    fig.write_html(\"output/GPS_vs_Baro.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "display_barom_vs_gps(raw_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_ina(raw_dfs):\n",
    "\n",
    "    df_ina, df_gps, df_baro, df_pas, df_ms, df_imu, df_brake = raw_dfs\n",
    "    \n",
    "    #df_ina = df_ina.sample(n=100000).sort_values('Datetime')\n",
    "    df_ina = df_ina.iloc[-100000:]\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=1,\n",
    "                        shared_xaxes=True,\n",
    "                        vertical_spacing=0.01,\n",
    "                       )\n",
    "\n",
    "\n",
    "    fig.update_layout(hovermode=\"x unified\")\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_ina[\"Datetime\"],\n",
    "        y=df_ina[\"Power\"],\n",
    "        name=\"Power\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=df_ina[\"Datetime\"],\n",
    "        y=df_ina[\"Power_averaged\"],\n",
    "        name=\"Power Averaged\",\n",
    "        hoverinfo='y'),\n",
    "        row=1, col=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    fig.write_html(\"output/ina.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "display_ina(raw_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display 3D plot of trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_3d_plot(raw_dfs_test[1], raw_dfs_test[2], raw_dfs_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group power into grid squares of longitude/latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_data_location(df):\n",
    "    step = 0.0002\n",
    "    to_bin = lambda x: np.floor(x / step) * step\n",
    "    df[\"latbin\"] = df.latitude.map(to_bin)\n",
    "    df[\"lonbin\"] = df.longitude.map(to_bin)\n",
    "    groups = df.groupby([\"latbin\", \"lonbin\"]).mean()\n",
    "    return groups\n",
    "\n",
    "def group_data_time_interval(df):\n",
    "    groups = df.groupby(pd.Grouper(key=\"Datetime\", freq=\"1s\")).mean()\n",
    "    #df[\"Datetime\"] = df.index\n",
    "    groups = groups.dropna()\n",
    "    return groups\n",
    "\n",
    "df_ml_train_grouped = group_data_time_interval(df_ml_train)\n",
    "display_gps_positions_bins(df_ml_train_grouped)\n",
    "# df_ml_train_grouped = group_data_location(df_ml_train)\n",
    "# display_gps_positions_bins(df_ml_train_grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display distribution of power parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.histogram(raw_dfs_train[0], x=\"Power\", title='Power Distribution')\n",
    "fig.update_xaxes(title_text=\"Power[mW]\")\n",
    "fig.show()\n",
    "fig = px.histogram(raw_dfs_train[0], x=\"Voltage_V\", title='Battery Voltage Distribution')\n",
    "fig.update_xaxes(title_text=\"Voltage[V]\")\n",
    "fig.show()\n",
    "fig = px.histogram(raw_dfs_train[0], x=\"Current\", title='Current Distribution')\n",
    "fig.update_xaxes(title_text=\"Current[mA]\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display speed vs power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.line(raw_dfs_train[4], x=\"Datetime\", y=\"filtered_motor_rpm\", title='Speed vs Time').show()\n",
    "fig =  px.line(raw_dfs_train[4], x=\"Datetime\", y=\"motor_rpm\", title='Speed vs Time').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Lat/Long vs power(unbinned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latitude_start_pt, longitude_start_pt = 51.45282, -0.2275045\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "L1 = [51.45282, -0.2275045]\n",
    "def plot_proximity_to_start_point(df):\n",
    "    df['distance'] = df[['latitude', 'longitude']].sub(np.array(L1)).pow(2).sum(1).pow(0.5)\n",
    "    \n",
    "    fig = px.line(df, x=\"Datetime_copy\", y=\"distance\", title='Distance from start point').show()\n",
    "    \n",
    "    time_series = df['distance']\n",
    "    indices = find_peaks(-time_series, distance = 2000,height=-0.0005)[0]\n",
    "    \n",
    "    \n",
    "    df[\"loop_number\"] = 0\n",
    "    for i in range(len(indices)-1):\n",
    "        rows = range(indices[i],indices[i+1])\n",
    "        \n",
    "        df.loc[rows, \"loop_number\"] = i+1\n",
    "    \n",
    "\n",
    "    fig = px.line(df, x=\"latitude\", y=\"Power\", color='loop_number', title= \"Power profile on each loop\")\n",
    "    fig.write_html(\"output/Power_profile_on_each_loop.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "    \n",
    "plot_proximity_to_start_point(df_ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Energy Consumption each loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_energy_consumption_for_each_loop(df_ml):\n",
    "    energies_per_loop = []\n",
    "    for i in df_ml['loop_number'].unique():\n",
    "        \n",
    "        df_loop = df_ml[df_ml[\"loop_number\"] == i]\n",
    "        energy_in_loop = energy_from_power_time(df_loop[\"Datetime\"], df_loop[\"Power\"])\n",
    "        energies_per_loop.append((i,energy_in_loop))\n",
    "                                 \n",
    "    return pd.DataFrame(energies_per_loop, columns=['Loop_number', 'Energy_Kilo_Joules'])\n",
    "\n",
    "def plot_energy_consumption_per_loop(df_ml):\n",
    "    energies_per_loop = calculate_energy_consumption_for_each_loop(df_ml)       \n",
    "    fig = px.line(energies_per_loop, x=\"Loop_number\", y=\"Energy_Kilo_Joules\", title='Energy consumption of each loop around Putney Heath')\n",
    "    fig.update_layout(yaxis_range=[48,65])\n",
    "    fig.write_html(\"output/Energy_consumption_per_loop.html\")\n",
    "    fig.show()\n",
    "\n",
    "plot_energy_consumption_per_loop(df_ml_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display Lat/Long vs power(binned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_proximity_to_start_point_binned(df):\n",
    "    df['distance'] = df[['latitude', 'longitude']].sub(np.array(L1)).pow(2).sum(1).pow(0.5)\n",
    "    \n",
    "    \n",
    "    time_series = df['distance']\n",
    "    indices = find_peaks(-time_series,\n",
    "                         distance = 2000,\n",
    "                         height=-0.0005)[0]\n",
    "    \n",
    "    \n",
    "    df[\"ts\"] = df.index.values\n",
    "    df[\"loop_number\"] = 0\n",
    "    for i in range(len(indices)-1):\n",
    "        \n",
    "        start_time = df[\"ts\"].iloc[indices[i]]\n",
    "        end_time = df[\"ts\"].iloc[indices[i+1]]        \n",
    "        df.loc[start_time:end_time, \"loop_number\"] = i+1\n",
    "    \n",
    "    fig = px.line(df, x=\"latitude\", y=\"Power\", color='loop_number', title= \"Power profile on each loop\")\n",
    "    fig.write_html(\"output/Power_profile_on_each_loop_binned.html\")\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "plot_proximity_to_start_point_binned(df_ml_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig =  px.scatter(df_ml_train, x=\"latitude\", y=\"Power\", title='Latitude vs Power').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display IMU data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def display_imu_plots(df_imu):\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=df_imu[\"gyro_x\"],\n",
    "                             y=df_imu[\"acceleration_x\"],\n",
    "                             mode='markers',\n",
    "                             marker=dict(size=1),\n",
    "                             name='Raw data'\n",
    "                            )\n",
    "                 )\n",
    "    \n",
    "    fig.add_trace(go.Scatter(x=df_imu[\"gyro_x_filtered\"], \n",
    "                             y=df_imu[\"acceleration_x_filtered\"],\n",
    "                             mode='markers',\n",
    "                             marker=dict(size=1),\n",
    "                             name='Filtered data'\n",
    "\n",
    "                            )\n",
    "                 )\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"IMU Acceleration vs Angular velocity(gyro)\",\n",
    "        xaxis_title=\"Angular Velocity[rad/s]\",\n",
    "        yaxis_title=\"Acceleration[m/s^2]\",\n",
    "    )\n",
    "    fig.show()\n",
    "                  \n",
    "display_imu_plots(raw_dfs_train[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(raw_dfs_train[5], x=\"gyro_x\", y=\"acceleration_x\", title='Acceleration[m/s^2] vs Angular velocity[rad/s]')\n",
    "fig.update_traces(marker=dict(size=1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(raw_dfs_train[5], x=\"Datetime\", y=[\"acceleration_x\",\"acceleration_x_filtered\"], title='Acceleration over Time').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line(df_ml_train, x=\"Datetime\", y=[\"Power\",\"Power_averaged\"], title='Power over Time').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train ML model XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "xgbr = do_ml(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot predicted and actual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_predictions_xgboost(xgbr, df_ml_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create test of 15 minute runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_short_runs(xgbr, df_ml_test, predictor, scaler = None, test_length = 600, row_timestep = 0.0, show_plots=False):\n",
    "    test_n_rows = test_length/row_timestep\n",
    "\n",
    "    n_rows = len(df_ml_test.index)\n",
    "\n",
    "\n",
    "    tests = np.array_split(df_ml_test, n_rows//test_n_rows)\n",
    "\n",
    "    \n",
    "    scores = []\n",
    "    for test in tests:\n",
    "        error = predictor(xgbr, test, plot=show_plots)\n",
    "        scores.append(error)\n",
    "        \n",
    "    return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = test_short_runs(xgbr, df_ml_test, make_predictions_xgboost, test_length = 600, row_timestep = 0.01, show_plots=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=scores, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display interesting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_interesting_variables(df_ml_test, xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Neural Network with multidimensional input to do regression\n",
    "Currently, we pass rows into the XG boost model. What if we could insert a snap shot of 10 seconds of data containing all the features, and calculating the energy consumption of this snapshot? Its like a photograph used in Deep Neural Networks: 2 dimensional input. Run the StructuredDataRegressor.\n",
    "You can also leave the epochs unspecified for an adaptive number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nFEzlsEZaz1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the structured data regressor.\n",
    "reg = ak.StructuredDataRegressor(\n",
    "    #overwrite=True,\n",
    "    max_trials=3\n",
    ")  # It tries 3 different models.\n",
    "\n",
    "\n",
    "\n",
    "x, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "# Feed the structured data regressor with training data.\n",
    "with tf.device('/gpu:0'):\n",
    "    reg.fit(x,\n",
    "            y,\n",
    "            epochs=5\n",
    "           )\n",
    "\n",
    "model = reg.export_model()\n",
    "\n",
    "print(type(model))  # <class 'tensorflow.python.keras.engine.training.Model'>\n",
    "\n",
    "try:\n",
    "    model.save(\"model_autokeras\", save_format=\"tf\")\n",
    "except Exception:\n",
    "    model.save(\"model_autokeras.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predicted_data_autokeras(model, df_ml_test,scaler):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    x = scaler.transform(x)\n",
    "    ypred = model.predict(x).flatten()    \n",
    "\n",
    "    print_power_consumption_score(df_ml_test[\"Datetime\"], y, ypred)\n",
    "    plot_predicted_data(df_ml_test[\"Datetime\"], y, ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predicted_data_autokeras(reg, df_ml_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Scikit learn simple functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import svm\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "df_ml_train.dropna(subset=params_x_for_ml, inplace=True)\n",
    "x, y = split_x_y(df_ml_train, params_x_for_ml, params_y_for_ml)\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "\n",
    "#reg = svm.SVR().fit(x, y)\n",
    "reg = LinearRegression().fit(x, y)\n",
    "print(\"Score: \",reg.score(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_predicted_data_autokeras(reg, df_ml_test, scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_predicted_data_sk(model, df_ml_test):\n",
    "    x, y  = split_x_y(df_ml_test, params_x_for_ml, params_y_for_ml)\n",
    "    x = scaler.transform(x)\n",
    "    ypred = model.predict(x)\n",
    "    error = print_power_consumption_score(df_ml_test[\"Datetime\"], y, ypred)\n",
    "    return y, ypred, error\n",
    "\n",
    "def make_predictions_sk(model, df_ml_test, plot=True):\n",
    "    y, ypred, error = score_predicted_data_sk(model, df_ml_test)\n",
    "    if plot == True:\n",
    "        plot_predicted_data(df_ml_test[\"Datetime\"], y, ypred)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scores = test_short_runs(reg, df_ml_test, make_predictions_sk, test_length = 5*60, row_timestep = 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = np.clip(scores, -100, 100 )\n",
    "sns.displot(x=scores, kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now try to use the ImageRegression for autokeras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5HmCvDu2EtQ"
   },
   "source": [
    "To make this tutorial easy to follow, we just treat MNIST dataset as a\n",
    "regression dataset. It means we will treat prediction targets of MNIST dataset,\n",
    "which are integers ranging from 0 to 9 as numerical values, so that they can be\n",
    "directly used as the regression targets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_for_autokeras_image_regressor(df_ml):\n",
    "    \n",
    "    chunks = np.array_split(\n",
    "        df_ml[params_x_for_ml+[params_y_for_ml]].to_numpy(),\n",
    "        range(0, len(df_ml), 100) # 100 x 0.01 seconds chunks = 1 second chunks\n",
    "    )\n",
    "\n",
    "    chunks = chunks[1:-1] # Drop the first and last chunk that may be shorter\n",
    "\n",
    "    energies = []\n",
    "    chunks_edited = []\n",
    "\n",
    "    time_interval = 0.010 # seconds\n",
    "    for chunk in chunks:\n",
    "        powers = chunk[:, -1] # for last column in mW\n",
    "        energy = np.sum(powers * time_interval / 1000000) # in KiloJoules\n",
    "        chunks_edited.append(chunk[:, :-1]) # for all but last column\n",
    "        energies.append(energy)\n",
    "\n",
    "    \n",
    "    fig =  px.line(y=energies, title='Energies islotated').show()\n",
    "\n",
    "\n",
    "\n",
    "    y = np.array(energies)\n",
    "    x = np.array(chunks_edited)\n",
    "\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_ml_image_regression(x, y):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.10, random_state=42)\n",
    "\n",
    "    # Initialize the image regressor.\n",
    "    reg = ak.ImageRegressor(overwrite=True,\n",
    "                            max_trials=3\n",
    "                           )\n",
    "    # Feed the image regressor with training data.\n",
    "    reg.fit(x, y)\n",
    "\n",
    "    # Evaluate the best model with testing data.\n",
    "    #print(reg.evaluate(X_test, y_test))\n",
    "    \n",
    "    return reg\n",
    "\n",
    "reg  = do_ml_image_regression(*prep_for_autokeras_image_regressor(df_ml_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict with the best model.\n",
    "\n",
    "def predict_and_score(reg, df_ml_test):\n",
    "    x, y  = prep_for_autokeras_image_regressor(df_ml_test)\n",
    "    predicted_y = reg.predict(x)\n",
    "\n",
    "    fig =  px.line(y=predicted_y.flatten().tolist(), title='predicted_y').show()\n",
    "\n",
    "\n",
    "    length = len(y)\n",
    "\n",
    "    # intialise data of lists.\n",
    "    data = {'Energies':predicted_y.flatten().tolist() + y.tolist(),\n",
    "            'type_of_data':length * [\"Predicted\"] + length * [\"Actual\"],\n",
    "            \"Index\": list(range(length))*2}\n",
    "\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Print the output.\n",
    "    fig = px.line(df, x = \"Index\", y=\"Energies\", color=\"type_of_data\", title='Energies').show()\n",
    "\n",
    "    get_energy_error(sum(predicted_y), sum(y))\n",
    "    \n",
    "predict_and_score(reg, df_ml_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Masters",
   "language": "python",
   "name": "masters"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
